{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":407317,"datasetId":181273,"databundleVersionId":422498}],"dockerImageVersionId":31287,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Notebook-3: Conference Experiments (Ablations + Threshold Tuning + Robustness)\n\nThis notebook runs publishable experiments on LGG MRI segmentation:\n- Ablation A: Self-attention ON vs OFF (same backbone)\n- Ablation B: Transfer learning strategy (encoder frozen vs full fine-tune)\n- Threshold sweep: best threshold for Dice/IoU on validation\n- Patient-level metrics + bootstrap 95% CI\n- Paper-ready plots + LaTeX tables exported to `/kaggle/working/paper_outputs/`\n\nPrerequisites:\n- Dataset attached (kaggle_3m).\n- This notebook is self-contained (rebuilds df + splits).\n","metadata":{}},{"cell_type":"code","source":"import os, re, glob, random, math, time\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom torchvision.models import resnet34, ResNet34_Weights\nimport torchvision.transforms.functional as TF\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-28T06:50:14.102557Z","iopub.execute_input":"2026-02-28T06:50:14.103216Z","iopub.status.idle":"2026-02-28T06:50:21.382164Z","shell.execute_reply.started":"2026-02-28T06:50:14.103186Z","shell.execute_reply":"2026-02-28T06:50:21.381588Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# -------------------------------\n# ✅ GLOBAL PAPER-STYLE SETTINGS\n# -------------------------------\nplt.rcParams.update({\n    \"font.family\": \"serif\",\n    \"font.serif\": [\"Times New Roman\", \"Times\", \"DejaVu Serif\"],\n    \"font.size\": 12,\n\n    \"axes.labelsize\": 13,\n    \"axes.titlesize\": 13,\n    \"axes.linewidth\": 1.2,\n\n    \"xtick.labelsize\": 11,\n    \"ytick.labelsize\": 11,\n    \"xtick.major.size\": 6,\n    \"ytick.major.size\": 6,\n    \"xtick.minor.size\": 3,\n    \"ytick.minor.size\": 3,\n\n    \"legend.fontsize\": 11,\n    \"legend.frameon\": True,\n    \"legend.edgecolor\": \"0.4\",\n\n    \"grid.linestyle\": \":\",\n    \"grid.linewidth\": 0.7,\n    \"grid.alpha\": 0.85,\n})\n\ndef paper_axes(ax):\n    ax.minorticks_on()\n    ax.grid(True, which=\"major\", linestyle=\":\", linewidth=0.8)\n    ax.grid(True, which=\"minor\", linestyle=\":\", linewidth=0.5, alpha=0.7)\n\n    for spine in ax.spines.values():\n        spine.set_linewidth(1.2)\n\n    ax.tick_params(which=\"both\", direction=\"in\", top=True, right=True)\n\n# -------------------------------\n# Reproducibility\n# -------------------------------\nSEED = 7\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\n\ntorch.backends.cudnn.deterministic = False\ntorch.backends.cudnn.benchmark = True\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-28T06:50:21.383465Z","iopub.execute_input":"2026-02-28T06:50:21.384162Z","iopub.status.idle":"2026-02-28T06:50:21.396119Z","shell.execute_reply.started":"2026-02-28T06:50:21.384135Z","shell.execute_reply":"2026-02-28T06:50:21.395555Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"CFG = {\n    \"img_size\": 256,\n    \"batch_size\": 16,\n    \"num_workers\": 2,\n    \"epochs\": 8,                 # keep smaller for ablation sweep\n    \"lr\": 3e-4,\n    \"weight_decay\": 1e-4,\n    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n    \"threshold_default\": 0.5,\n\n    # speed knobs\n    \"fast_dev_run\": False,       # True = tiny subset quick check\n    \"fast_train_slices\": 400,\n    \"fast_val_slices\": 200,\n}\n\nOUT_DIR = Path(\"/kaggle/working/paper_outputs\")\nOUT_DIR.mkdir(parents=True, exist_ok=True)\n\nCFG\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-28T06:50:21.397068Z","iopub.execute_input":"2026-02-28T06:50:21.397581Z","iopub.status.idle":"2026-02-28T06:50:21.451952Z","shell.execute_reply.started":"2026-02-28T06:50:21.397531Z","shell.execute_reply":"2026-02-28T06:50:21.451182Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"{'img_size': 256,\n 'batch_size': 16,\n 'num_workers': 2,\n 'epochs': 8,\n 'lr': 0.0003,\n 'weight_decay': 0.0001,\n 'device': 'cuda',\n 'threshold_default': 0.5,\n 'fast_dev_run': False,\n 'fast_train_slices': 400,\n 'fast_val_slices': 200}"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"## Data loading (slice-level), patient-safe split\n\nWe rebuild the slice dataframe from `kaggle_3m` and create a patient-level split\n(train/val/test). This matches the anti-leakage protocol.\n","metadata":{}},{"cell_type":"code","source":"KAGGLE_INPUT = Path(\"/kaggle/input\")\ncandidates = list(KAGGLE_INPUT.glob(\"**/kaggle_3m\"))\nprint(\"Found candidates:\", [str(p) for p in candidates[:10]])\n\nif len(candidates) == 0:\n    raise FileNotFoundError(\"Could not find 'kaggle_3m' under /kaggle/input. Attach the dataset.\")\nDATA_ROOT = candidates[0]\nDATA_ROOT\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-28T06:50:21.453710Z","iopub.execute_input":"2026-02-28T06:50:21.454385Z","iopub.status.idle":"2026-02-28T06:51:01.539555Z","shell.execute_reply.started":"2026-02-28T06:50:21.454360Z","shell.execute_reply":"2026-02-28T06:51:01.538965Z"}},"outputs":[{"name":"stdout","text":"Found candidates: ['/kaggle/input/datasets/mateuszbuda/lgg-mri-segmentation/kaggle_3m', '/kaggle/input/datasets/mateuszbuda/lgg-mri-segmentation/lgg-mri-segmentation/kaggle_3m']\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"PosixPath('/kaggle/input/datasets/mateuszbuda/lgg-mri-segmentation/kaggle_3m')"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"def to_key(path):\n    base = Path(path).name\n    if base.endswith(\"_mask.tif\"):\n        base = base.replace(\"_mask.tif\", \"\")\n    else:\n        base = base.replace(\".tif\", \"\")\n    return base\n\ndef patient_id_from_path(path):\n    return Path(path).parent.name\n\ndef slice_index_from_key(k):\n    m = re.search(r\"_(\\d+)$\", k)\n    return int(m.group(1)) if m else np.nan\n\nall_tifs = sorted(glob.glob(str(DATA_ROOT / \"*\" / \"*.tif\")))\nmask_tifs = sorted([p for p in all_tifs if p.endswith(\"_mask.tif\")])\nimg_tifs  = sorted([p for p in all_tifs if not p.endswith(\"_mask.tif\")])\n\nimg_map = {to_key(p): p for p in img_tifs}\nmsk_map = {to_key(p): p for p in mask_tifs}\nkeys = sorted(set(img_map.keys()) & set(msk_map.keys()))\n\ndf = pd.DataFrame({\n    \"key\": keys,\n    \"image_path\": [img_map[k] for k in keys],\n    \"mask_path\":  [msk_map[k] for k in keys],\n})\ndf[\"patient_id\"] = df[\"image_path\"].apply(patient_id_from_path)\ndf[\"slice_idx\"] = df[\"key\"].apply(slice_index_from_key)\ndf = df.sort_values([\"patient_id\", \"slice_idx\", \"key\"]).reset_index(drop=True)\n\nprint(\"Slices:\", len(df), \"| Patients:\", df[\"patient_id\"].nunique())\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-28T06:51:01.540460Z","iopub.execute_input":"2026-02-28T06:51:01.540719Z","iopub.status.idle":"2026-02-28T06:51:01.767248Z","shell.execute_reply.started":"2026-02-28T06:51:01.540696Z","shell.execute_reply":"2026-02-28T06:51:01.766686Z"}},"outputs":[{"name":"stdout","text":"Slices: 3929 | Patients: 110\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                       key                                         image_path  \\\n0  TCGA_CS_4941_19960909_1  /kaggle/input/datasets/mateuszbuda/lgg-mri-seg...   \n1  TCGA_CS_4941_19960909_2  /kaggle/input/datasets/mateuszbuda/lgg-mri-seg...   \n2  TCGA_CS_4941_19960909_3  /kaggle/input/datasets/mateuszbuda/lgg-mri-seg...   \n3  TCGA_CS_4941_19960909_4  /kaggle/input/datasets/mateuszbuda/lgg-mri-seg...   \n4  TCGA_CS_4941_19960909_5  /kaggle/input/datasets/mateuszbuda/lgg-mri-seg...   \n\n                                           mask_path             patient_id  \\\n0  /kaggle/input/datasets/mateuszbuda/lgg-mri-seg...  TCGA_CS_4941_19960909   \n1  /kaggle/input/datasets/mateuszbuda/lgg-mri-seg...  TCGA_CS_4941_19960909   \n2  /kaggle/input/datasets/mateuszbuda/lgg-mri-seg...  TCGA_CS_4941_19960909   \n3  /kaggle/input/datasets/mateuszbuda/lgg-mri-seg...  TCGA_CS_4941_19960909   \n4  /kaggle/input/datasets/mateuszbuda/lgg-mri-seg...  TCGA_CS_4941_19960909   \n\n   slice_idx  \n0          1  \n1          2  \n2          3  \n3          4  \n4          5  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>key</th>\n      <th>image_path</th>\n      <th>mask_path</th>\n      <th>patient_id</th>\n      <th>slice_idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TCGA_CS_4941_19960909_1</td>\n      <td>/kaggle/input/datasets/mateuszbuda/lgg-mri-seg...</td>\n      <td>/kaggle/input/datasets/mateuszbuda/lgg-mri-seg...</td>\n      <td>TCGA_CS_4941_19960909</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TCGA_CS_4941_19960909_2</td>\n      <td>/kaggle/input/datasets/mateuszbuda/lgg-mri-seg...</td>\n      <td>/kaggle/input/datasets/mateuszbuda/lgg-mri-seg...</td>\n      <td>TCGA_CS_4941_19960909</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>TCGA_CS_4941_19960909_3</td>\n      <td>/kaggle/input/datasets/mateuszbuda/lgg-mri-seg...</td>\n      <td>/kaggle/input/datasets/mateuszbuda/lgg-mri-seg...</td>\n      <td>TCGA_CS_4941_19960909</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TCGA_CS_4941_19960909_4</td>\n      <td>/kaggle/input/datasets/mateuszbuda/lgg-mri-seg...</td>\n      <td>/kaggle/input/datasets/mateuszbuda/lgg-mri-seg...</td>\n      <td>TCGA_CS_4941_19960909</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>TCGA_CS_4941_19960909_5</td>\n      <td>/kaggle/input/datasets/mateuszbuda/lgg-mri-seg...</td>\n      <td>/kaggle/input/datasets/mateuszbuda/lgg-mri-seg...</td>\n      <td>TCGA_CS_4941_19960909</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"patients = df[\"patient_id\"].drop_duplicates().tolist()\nrng = np.random.default_rng(SEED)\nrng.shuffle(patients)\n\nn = len(patients)\ntrain_pat = set(patients[: int(0.8*n)])\nval_pat   = set(patients[int(0.8*n): int(0.9*n)])\ntest_pat  = set(patients[int(0.9*n):])\n\ndef assign_split(pid):\n    if pid in train_pat: return \"train\"\n    if pid in val_pat: return \"val\"\n    return \"test\"\n\ndf[\"split\"] = df[\"patient_id\"].apply(assign_split)\n\nprint(df[\"split\"].value_counts())\nprint(df.groupby(\"split\")[\"patient_id\"].nunique())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-28T06:51:01.768126Z","iopub.execute_input":"2026-02-28T06:51:01.768344Z","iopub.status.idle":"2026-02-28T06:51:01.779466Z","shell.execute_reply.started":"2026-02-28T06:51:01.768324Z","shell.execute_reply":"2026-02-28T06:51:01.778907Z"}},"outputs":[{"name":"stdout","text":"split\ntrain    3068\ntest      435\nval       426\nName: count, dtype: int64\nsplit\ntest     11\ntrain    88\nval      11\nName: patient_id, dtype: int64\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## Torchvision augmentation (no cv2)\n\nWe keep a lightweight augmentation pipeline that is stable under NumPy 2.x.\n","metadata":{}},{"cell_type":"code","source":"class TorchvisionAugment:\n    def __init__(self, train=True):\n        self.train = train\n\n    def __call__(self, img, msk):\n        # img: numpy HWC uint8, msk: numpy HW uint8 {0,1}\n        img_t = TF.to_tensor(img)                      # (3,H,W) float32 [0,1]\n        msk_t = torch.from_numpy(msk).unsqueeze(0).float()\n\n        if self.train:\n            if torch.rand(1).item() < 0.5:\n                img_t = TF.hflip(img_t); msk_t = TF.hflip(msk_t)\n            if torch.rand(1).item() < 0.2:\n                img_t = TF.vflip(img_t); msk_t = TF.vflip(msk_t)\n\n            angle = float((torch.rand(1).item() - 0.5) * 24.0)  # [-12, 12]\n            img_t = TF.rotate(img_t, angle, interpolation=TF.InterpolationMode.BILINEAR)\n            msk_t = TF.rotate(msk_t, angle, interpolation=TF.InterpolationMode.NEAREST)\n\n            if torch.rand(1).item() < 0.25:\n                b = 0.9 + 0.2 * torch.rand(1).item()\n                c = 0.9 + 0.2 * torch.rand(1).item()\n                img_t = TF.adjust_brightness(img_t, b)\n                img_t = TF.adjust_contrast(img_t, c)\n\n            if torch.rand(1).item() < 0.15:\n                try:\n                    img_t = TF.gaussian_blur(img_t, kernel_size=[3, 3], sigma=[0.1, 1.2])\n                except Exception:\n                    pass\n\n        return img_t, msk_t\n\ntrain_tfms = TorchvisionAugment(train=True)\nval_tfms   = TorchvisionAugment(train=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-28T06:51:01.780492Z","iopub.execute_input":"2026-02-28T06:51:01.780790Z","iopub.status.idle":"2026-02-28T06:51:01.795073Z","shell.execute_reply.started":"2026-02-28T06:51:01.780768Z","shell.execute_reply":"2026-02-28T06:51:01.794235Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def load_tif(path):\n    return np.array(Image.open(path))\n\ndef to_mask01(msk):\n    if msk.ndim == 3:\n        m = msk[..., 0]\n    else:\n        m = msk\n    return (m > 0).astype(np.uint8)\n\nclass LGGSegDataset(Dataset):\n    def __init__(self, df, tfms=None):\n        self.df = df.reset_index(drop=True)\n        self.tfms = tfms\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        r = self.df.iloc[idx]\n        img = load_tif(r.image_path)\n        msk = to_mask01(load_tif(r.mask_path))\n\n        if img.ndim == 2:\n            img = np.stack([img, img, img], axis=-1)\n\n        if self.tfms is not None:\n            img_t, msk_t = self.tfms(img, msk)\n            return img_t.float(), msk_t.float()\n\n        img_t = torch.from_numpy(img).permute(2,0,1).float() / 255.0\n        msk_t = torch.from_numpy(msk).unsqueeze(0).float()\n        return img_t, msk_t\n\ntrain_df = df[df[\"split\"]==\"train\"].copy()\nval_df   = df[df[\"split\"]==\"val\"].copy()\ntest_df  = df[df[\"split\"]==\"test\"].copy()\n\nif CFG[\"fast_dev_run\"]:\n    train_df = train_df.sample(min(CFG[\"fast_train_slices\"], len(train_df)), random_state=SEED)\n    val_df   = val_df.sample(min(CFG[\"fast_val_slices\"], len(val_df)), random_state=SEED)\n    test_df  = test_df.sample(min(200, len(test_df)), random_state=SEED)\n\ntrain_ds = LGGSegDataset(train_df, tfms=train_tfms)\nval_ds   = LGGSegDataset(val_df, tfms=val_tfms)\ntest_ds  = LGGSegDataset(test_df, tfms=val_tfms)\n\ntrain_loader = DataLoader(train_ds, batch_size=CFG[\"batch_size\"], shuffle=True,\n                          num_workers=CFG[\"num_workers\"], pin_memory=True, drop_last=True)\nval_loader   = DataLoader(val_ds, batch_size=CFG[\"batch_size\"], shuffle=False,\n                          num_workers=CFG[\"num_workers\"], pin_memory=True)\ntest_loader  = DataLoader(test_ds, batch_size=CFG[\"batch_size\"], shuffle=False,\n                          num_workers=CFG[\"num_workers\"], pin_memory=True)\n\nlen(train_ds), len(val_ds), len(test_ds)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-28T06:51:01.795850Z","iopub.execute_input":"2026-02-28T06:51:01.796064Z","iopub.status.idle":"2026-02-28T06:51:01.814582Z","shell.execute_reply.started":"2026-02-28T06:51:01.796043Z","shell.execute_reply":"2026-02-28T06:51:01.813746Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(3068, 426, 435)"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"## Model family for ablations\n\nWe keep a single model family and toggle:\n- `use_attention`: True/False\n- `freeze_encoder`: True/False\n","metadata":{}},{"cell_type":"code","source":"class ConvBNReLU(nn.Module):\n    def __init__(self, in_ch, out_ch, k=3, p=1):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Conv2d(in_ch, out_ch, kernel_size=k, padding=p, bias=False),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True),\n        )\n    def forward(self, x):\n        return self.net(x)\n\nclass UpBlock(nn.Module):\n    def __init__(self, in_ch, skip_ch, out_ch):\n        super().__init__()\n        self.up = nn.ConvTranspose2d(in_ch, out_ch, kernel_size=2, stride=2)\n        self.conv1 = ConvBNReLU(out_ch + skip_ch, out_ch)\n        self.conv2 = ConvBNReLU(out_ch, out_ch)\n\n    def forward(self, x, skip):\n        x = self.up(x)\n        if x.shape[-2:] != skip.shape[-2:]:\n            x = F.interpolate(x, size=skip.shape[-2:], mode=\"bilinear\", align_corners=False)\n        x = torch.cat([x, skip], dim=1)\n        x = self.conv1(x)\n        x = self.conv2(x)\n        return x\n\nclass BottleneckMHSA(nn.Module):\n    def __init__(self, channels, heads=8, dropout=0.0):\n        super().__init__()\n        self.norm1 = nn.LayerNorm(channels)\n        self.attn = nn.MultiheadAttention(embed_dim=channels, num_heads=heads,\n                                          dropout=dropout, batch_first=True)\n        self.norm2 = nn.LayerNorm(channels)\n        self.ffn = nn.Sequential(\n            nn.Linear(channels, channels*4),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(channels*4, channels),\n        )\n\n    def forward(self, x):\n        b, c, h, w = x.shape\n        tokens = x.permute(0,2,3,1).reshape(b, h*w, c)\n        t = self.norm1(tokens)\n        attn_out, _ = self.attn(t, t, t, need_weights=False)\n        tokens = tokens + attn_out\n        t2 = self.norm2(tokens)\n        tokens = tokens + self.ffn(t2)\n        return tokens.reshape(b, h, w, c).permute(0,3,1,2)\n\nclass ResNet34UNetAttn(nn.Module):\n    def __init__(self, pretrained=True, use_attention=True, attn_heads=8):\n        super().__init__()\n        weights = ResNet34_Weights.IMAGENET1K_V1 if pretrained else None\n        self.encoder = resnet34(weights=weights)\n\n        self.conv1 = self.encoder.conv1\n        self.bn1   = self.encoder.bn1\n        self.relu  = self.encoder.relu\n        self.maxp  = self.encoder.maxpool\n\n        self.layer1 = self.encoder.layer1\n        self.layer2 = self.encoder.layer2\n        self.layer3 = self.encoder.layer3\n        self.layer4 = self.encoder.layer4\n\n        self.attn = BottleneckMHSA(512, heads=attn_heads) if use_attention else nn.Identity()\n\n        self.up3 = UpBlock(512, 256, 256)\n        self.up2 = UpBlock(256, 128, 128)\n        self.up1 = UpBlock(128, 64, 64)\n        self.up0 = UpBlock(64, 64, 64)\n\n        self.out = nn.Conv2d(64, 1, kernel_size=1)\n\n    def forward(self, x):\n        x0 = self.relu(self.bn1(self.conv1(x)))      # (B,64,128,128)\n        x1 = self.layer1(self.maxp(x0))              # (B,64,64,64)\n        x2 = self.layer2(x1)                         # (B,128,32,32)\n        x3 = self.layer3(x2)                         # (B,256,16,16)\n        x4 = self.layer4(x3)                         # (B,512,8,8)\n\n        x4 = self.attn(x4)\n\n        d3 = self.up3(x4, x3)\n        d2 = self.up2(d3, x2)\n        d1 = self.up1(d2, x1)\n        d0 = self.up0(d1, x0)\n\n        d0 = F.interpolate(d0, scale_factor=2, mode=\"bilinear\", align_corners=False)\n        return self.out(d0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-28T06:51:01.815461Z","iopub.execute_input":"2026-02-28T06:51:01.815773Z","iopub.status.idle":"2026-02-28T06:51:01.829719Z","shell.execute_reply.started":"2026-02-28T06:51:01.815751Z","shell.execute_reply":"2026-02-28T06:51:01.829100Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def set_encoder_trainable(model, trainable: bool):\n    for p in model.encoder.parameters():\n        p.requires_grad = trainable\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-28T06:51:01.831769Z","iopub.execute_input":"2026-02-28T06:51:01.832008Z","iopub.status.idle":"2026-02-28T06:51:01.843679Z","shell.execute_reply.started":"2026-02-28T06:51:01.831974Z","shell.execute_reply":"2026-02-28T06:51:01.842948Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"bce = nn.BCEWithLogitsLoss()\n\nclass DiceLoss(nn.Module):\n    def __init__(self, eps=1e-7):\n        super().__init__()\n        self.eps = eps\n    def forward(self, logits, targets):\n        probs = torch.sigmoid(logits)\n        num = 2.0 * (probs * targets).sum(dim=(2,3))\n        den = (probs + targets).sum(dim=(2,3)) + self.eps\n        return 1.0 - (num / den).mean()\n\ndef total_loss(logits, targets):\n    return 0.6 * bce(logits, targets) + 0.4 * DiceLoss()(logits, targets)\n\n@torch.no_grad()\ndef dice_iou_from_probs(probs_bin, targets, eps=1e-7):\n    # probs_bin, targets: (B,1,H,W) in {0,1}\n    inter = (probs_bin * targets).sum(dim=(2,3))\n    dice = (2*inter) / (probs_bin.sum(dim=(2,3)) + targets.sum(dim=(2,3)) + eps)\n    union = (probs_bin + targets - probs_bin*targets).sum(dim=(2,3)) + eps\n    iou = inter / union\n    return dice.squeeze(1), iou.squeeze(1)  # (B,), (B,)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-28T06:51:01.844449Z","iopub.execute_input":"2026-02-28T06:51:01.844690Z","iopub.status.idle":"2026-02-28T06:51:01.854522Z","shell.execute_reply.started":"2026-02-28T06:51:01.844668Z","shell.execute_reply":"2026-02-28T06:51:01.853833Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"@torch.no_grad()\ndef evaluate_slice_and_patient(model, loader, device, threshold=0.5, df_ref=None):\n    model.eval()\n    losses = []\n    slice_rows = []\n\n    # We need keys/patient_id mapping -> align to loader order\n    # Simplest: build an iterator over df_ref in same order as dataset df\n    assert df_ref is not None, \"Pass df_ref matching the dataset used for this loader.\"\n\n    ptr = 0\n    for xb, yb in loader:\n        bs = xb.size(0)\n        batch_df = df_ref.iloc[ptr:ptr+bs]\n        ptr += bs\n\n        xb = xb.to(device, non_blocking=True)\n        yb = yb.to(device, non_blocking=True)\n\n        logits = model(xb)\n        loss = total_loss(logits, yb).item()\n\n        probs = torch.sigmoid(logits)\n        probs_bin = (probs > threshold).float()\n\n        dice_b, iou_b = dice_iou_from_probs(probs_bin, yb)\n\n        losses.append(loss)\n        for i in range(bs):\n            slice_rows.append({\n                \"key\": batch_df.iloc[i][\"key\"],\n                \"patient_id\": batch_df.iloc[i][\"patient_id\"],\n                \"dice\": float(dice_b[i].item()),\n                \"iou\": float(iou_b[i].item()),\n                \"gt_area\": float(yb[i,0].sum().item()),\n                \"pred_area\": float(probs_bin[i,0].sum().item()),\n            })\n\n    slice_df = pd.DataFrame(slice_rows)\n    patient_df = (slice_df.groupby(\"patient_id\")\n                  .agg(dice=(\"dice\",\"mean\"), iou=(\"iou\",\"mean\"))\n                  .reset_index())\n\n    out = {\n        \"loss\": float(np.mean(losses)),\n        \"slice_dice_mean\": float(slice_df[\"dice\"].mean()),\n        \"slice_iou_mean\": float(slice_df[\"iou\"].mean()),\n        \"patient_dice_mean\": float(patient_df[\"dice\"].mean()),\n        \"patient_iou_mean\": float(patient_df[\"iou\"].mean()),\n        \"slice_df\": slice_df,\n        \"patient_df\": patient_df,\n    }\n    return out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-28T06:51:01.855460Z","iopub.execute_input":"2026-02-28T06:51:01.855837Z","iopub.status.idle":"2026-02-28T06:51:01.868295Z","shell.execute_reply.started":"2026-02-28T06:51:01.855807Z","shell.execute_reply":"2026-02-28T06:51:01.867591Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def train_one_epoch(model, loader, optimizer, scaler, device):\n    model.train()\n    losses = []\n    for xb, yb in loader:\n        xb = xb.to(device, non_blocking=True)\n        yb = yb.to(device, non_blocking=True)\n\n        optimizer.zero_grad(set_to_none=True)\n        with torch.amp.autocast(device_type=\"cuda\", enabled=(device==\"cuda\")):\n            logits = model(xb)\n            loss = total_loss(logits, yb)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        losses.append(loss.item())\n    return float(np.mean(losses))\n\ndef fit_model(config, train_loader, val_loader, train_df_ref, val_df_ref):\n    device = CFG[\"device\"]\n    model = ResNet34UNetAttn(\n        pretrained=True,\n        use_attention=config[\"use_attention\"],\n        attn_heads=8\n    ).to(device)\n\n    # Freeze or fine-tune\n    set_encoder_trainable(model, trainable=(not config[\"freeze_encoder\"]))\n\n    optimizer = torch.optim.AdamW(\n        filter(lambda p: p.requires_grad, model.parameters()),\n        lr=CFG[\"lr\"],\n        weight_decay=CFG[\"weight_decay\"]\n    )\n    scaler = torch.amp.GradScaler(enabled=(device==\"cuda\"))\n\n    best = {\"val_patient_dice\": -1}\n    history = []\n\n    ckpt_name = f\"best_attn{int(config['use_attention'])}_freeze{int(config['freeze_encoder'])}.pt\"\n    ckpt_path = OUT_DIR / ckpt_name\n\n    for epoch in range(1, CFG[\"epochs\"]+1):\n        t0 = time.time()\n        tr_loss = train_one_epoch(model, train_loader, optimizer, scaler, device)\n        val = evaluate_slice_and_patient(model, val_loader, device, threshold=CFG[\"threshold_default\"], df_ref=val_df_ref)\n\n        row = {\n            \"epoch\": epoch,\n            \"train_loss\": tr_loss,\n            \"val_loss\": val[\"loss\"],\n            \"val_slice_dice\": val[\"slice_dice_mean\"],\n            \"val_patient_dice\": val[\"patient_dice_mean\"],\n            \"val_patient_iou\": val[\"patient_iou_mean\"],\n            \"sec\": time.time() - t0,\n            **config\n        }\n        history.append(row)\n\n        if val[\"patient_dice_mean\"] > best[\"val_patient_dice\"]:\n            best = {\n                \"val_patient_dice\": val[\"patient_dice_mean\"],\n                \"val_patient_iou\": val[\"patient_iou_mean\"],\n                \"epoch\": epoch,\n                \"ckpt_path\": str(ckpt_path)\n            }\n            torch.save({\"model\": model.state_dict(), \"config\": config, \"CFG\": CFG}, ckpt_path)\n\n        print(\n            f\"Epoch {epoch:02d} | attn={config['use_attention']} freeze={config['freeze_encoder']} | \"\n            f\"tr_loss={tr_loss:.4f} | val_patient_dice={val['patient_dice_mean']:.4f} | best={best['val_patient_dice']:.4f}\"\n        )\n\n    return pd.DataFrame(history), best\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-28T06:51:01.869152Z","iopub.execute_input":"2026-02-28T06:51:01.869448Z","iopub.status.idle":"2026-02-28T06:51:01.882146Z","shell.execute_reply.started":"2026-02-28T06:51:01.869419Z","shell.execute_reply":"2026-02-28T06:51:01.881525Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## Main ablation grid (2×2)\n\nWe run 4 experiments:\n- Attention ON/OFF\n- Encoder Frozen (transfer as feature extractor) vs Full fine-tuning\n\nPrimary selection metric: **patient-level mean Dice on validation**.\n","metadata":{}},{"cell_type":"code","source":"device = CFG[\"device\"]\n\n# IMPORTANT: We need df_ref in the same order as dataset internal df\ntrain_df_ref = train_df.reset_index(drop=True)\nval_df_ref   = val_df.reset_index(drop=True)\ntest_df_ref  = test_df.reset_index(drop=True)\n\nexperiments = [\n    {\"use_attention\": False, \"freeze_encoder\": True,  \"name\": \"NoAttn_Frozen\"},\n    {\"use_attention\": False, \"freeze_encoder\": False, \"name\": \"NoAttn_Finetune\"},\n    {\"use_attention\": True,  \"freeze_encoder\": True,  \"name\": \"Attn_Frozen\"},\n    {\"use_attention\": True,  \"freeze_encoder\": False, \"name\": \"Attn_Finetune\"},\n]\n\nall_hist = []\nbest_rows = []\n\nfor cfg_exp in experiments:\n    print(\"\\n\" + \"=\"*80)\n    print(\"Running:\", cfg_exp)\n\n    hist_df, best = fit_model(cfg_exp, train_loader, val_loader, train_df_ref, val_df_ref)\n    hist_df[\"exp_name\"] = cfg_exp[\"name\"]\n    all_hist.append(hist_df)\n\n    best_rows.append({\n        \"exp_name\": cfg_exp[\"name\"],\n        \"use_attention\": cfg_exp[\"use_attention\"],\n        \"freeze_encoder\": cfg_exp[\"freeze_encoder\"],\n        \"best_epoch\": best[\"epoch\"],\n        \"best_val_patient_dice\": best[\"val_patient_dice\"],\n        \"best_val_patient_iou\": best[\"val_patient_iou\"],\n        \"ckpt_path\": best[\"ckpt_path\"],\n    })\n\nhist_all = pd.concat(all_hist, ignore_index=True)\nbest_df = pd.DataFrame(best_rows).sort_values(\"best_val_patient_dice\", ascending=False).reset_index(drop=True)\n\nbest_df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-28T06:51:01.883012Z","iopub.execute_input":"2026-02-28T06:51:01.883245Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nRunning: {'use_attention': False, 'freeze_encoder': True, 'name': 'NoAttn_Frozen'}\nDownloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 83.3M/83.3M [00:00<00:00, 218MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 01 | attn=False freeze=True | tr_loss=0.5525 | val_patient_dice=0.1874 | best=0.1874\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"## Threshold tuning (validation)\n\nWe sweep thresholds on the best model and select the threshold maximizing **patient-level Dice** on validation.\nThis produces a clean plot and a single threshold to report in the paper.\n","metadata":{}},{"cell_type":"code","source":"best_ckpt_path = best_df.loc[0, \"ckpt_path\"]\nbest_config = experiments[[e[\"name\"] for e in experiments].index(best_df.loc[0, \"exp_name\"])]\n\nprint(\"Best model:\", best_df.loc[0, \"exp_name\"])\nprint(\"Checkpoint:\", best_ckpt_path)\n\nbest_model = ResNet34UNetAttn(pretrained=True,\n                             use_attention=best_config[\"use_attention\"],\n                             attn_heads=8).to(device)\n\nckpt = torch.load(best_ckpt_path, map_location=device)\nbest_model.load_state_dict(ckpt[\"model\"])\nbest_model.eval();\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"@torch.no_grad()\ndef threshold_sweep(model, loader, device, thresholds, df_ref):\n    rows = []\n    for t in thresholds:\n        out = evaluate_slice_and_patient(model, loader, device, threshold=float(t), df_ref=df_ref)\n        rows.append({\n            \"threshold\": float(t),\n            \"patient_dice\": out[\"patient_dice_mean\"],\n            \"patient_iou\": out[\"patient_iou_mean\"],\n        })\n    return pd.DataFrame(rows)\n\nthresholds = np.linspace(0.1, 0.9, 17)\nsweep_df = threshold_sweep(best_model, val_loader, device, thresholds, df_ref=val_df_ref)\n\nbest_t = float(sweep_df.loc[sweep_df[\"patient_dice\"].idxmax(), \"threshold\"])\nprint(\"Best threshold by val patient Dice:\", best_t)\n\nsweep_df.head()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(13, 6))\npaper_axes(ax)\n\nax.plot(sweep_df[\"threshold\"], sweep_df[\"patient_dice\"], lw=2.2, label=\"Val patient Dice\")\nax.plot(sweep_df[\"threshold\"], sweep_df[\"patient_iou\"],  lw=2.2, label=\"Val patient IoU\")\nax.set_xlabel(\"Threshold\")\nax.set_ylabel(\"Score\")\nax.set_title(\"Validation threshold sweep (best checkpoint)\")\nax.legend(loc=\"lower right\")\n\nplt.tight_layout()\nplt.savefig(OUT_DIR / \"fig_threshold_sweep.png\", dpi=300, bbox_inches=\"tight\")\nplt.savefig(OUT_DIR / \"fig_threshold_sweep.pdf\", dpi=300, bbox_inches=\"tight\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Final test evaluation + bootstrap 95% CI (patient-level)\n\nWe report patient-level mean Dice/IoU on the held-out test set with bootstrap confidence intervals.\nThis is a common, paper-friendly way to report reliability for limited-size medical datasets.\n","metadata":{}},{"cell_type":"code","source":"test_out = evaluate_slice_and_patient(best_model, test_loader, device, threshold=best_t, df_ref=test_df_ref)\n\nprint(\"Test patient Dice:\", test_out[\"patient_dice_mean\"])\nprint(\"Test patient IoU :\", test_out[\"patient_iou_mean\"])\n\ntest_patient_df = test_out[\"patient_df\"].copy()\ntest_patient_df.head()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def bootstrap_ci(x, n_boot=5000, ci=95, seed=7):\n    rng = np.random.default_rng(seed)\n    x = np.asarray(x, dtype=np.float64)\n    n = len(x)\n    boots = []\n    for _ in range(n_boot):\n        samp = rng.choice(x, size=n, replace=True)\n        boots.append(samp.mean())\n    boots = np.array(boots)\n    lo = np.percentile(boots, (100-ci)/2)\n    hi = np.percentile(boots, 100 - (100-ci)/2)\n    return float(x.mean()), float(lo), float(hi)\n\ndice_mean, dice_lo, dice_hi = bootstrap_ci(test_patient_df[\"dice\"].values)\niou_mean,  iou_lo,  iou_hi  = bootstrap_ci(test_patient_df[\"iou\"].values)\n\nprint(f\"Patient Dice mean (95% CI): {dice_mean:.4f} [{dice_lo:.4f}, {dice_hi:.4f}]\")\nprint(f\"Patient IoU  mean (95% CI): {iou_mean:.4f} [{iou_lo:.4f}, {iou_hi:.4f}]\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(13, 6))\npaper_axes(ax)\n\nax.hist(test_patient_df[\"dice\"], bins=15, alpha=0.85, color=\"0.35\")\nax.set_xlabel(\"Patient Dice\")\nax.set_ylabel(\"Number of patients\")\nax.set_title(\"Test-set patient Dice distribution (best model)\")\n\nplt.tight_layout()\nplt.savefig(OUT_DIR / \"fig_patient_dice_hist.png\", dpi=300, bbox_inches=\"tight\")\nplt.savefig(OUT_DIR / \"fig_patient_dice_hist.pdf\", dpi=300, bbox_inches=\"tight\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Export results: CSV + LaTeX table\n\nWe create:\n- `ablation_results.csv`\n- `ablation_results.tex`  (copy-paste into paper)\n- `test_metrics.csv`\n","metadata":{}},{"cell_type":"code","source":"# Take best val patient Dice per experiment\nbest_per_exp = (hist_all.sort_values(\"val_patient_dice\", ascending=False)\n                .groupby(\"exp_name\")\n                .head(1)\n                .sort_values(\"val_patient_dice\", ascending=False)\n                .reset_index(drop=True))\n\nablation_table = best_per_exp[[\n    \"exp_name\", \"use_attention\", \"freeze_encoder\",\n    \"epoch\", \"val_patient_dice\", \"val_patient_iou\", \"val_loss\"\n]].copy()\n\nablation_table.rename(columns={\n    \"epoch\": \"best_epoch\",\n    \"val_patient_dice\": \"val_patient_dice\",\n    \"val_patient_iou\": \"val_patient_iou\",\n    \"val_loss\": \"val_loss\"\n}, inplace=True)\n\nablation_table\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ablation_csv = OUT_DIR / \"ablation_results.csv\"\nablation_tex = OUT_DIR / \"ablation_results.tex\"\n\nablation_table.to_csv(ablation_csv, index=False)\n\n# Simple LaTeX export (clean)\nlatex_df = ablation_table.copy()\nlatex_df[\"use_attention\"] = latex_df[\"use_attention\"].map({True:\"Yes\", False:\"No\"})\nlatex_df[\"freeze_encoder\"] = latex_df[\"freeze_encoder\"].map({True:\"Frozen\", False:\"Fine-tune\"})\n\nlatex_str = latex_df.to_latex(index=False, float_format=lambda x: f\"{x:.4f}\")\nablation_tex.write_text(latex_str)\n\nprint(\"Saved:\")\nprint(\"-\", ablation_csv)\nprint(\"-\", ablation_tex)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_metrics = pd.DataFrame([{\n    \"best_model\": best_df.loc[0, \"exp_name\"],\n    \"best_threshold\": best_t,\n    \"test_patient_dice_mean\": dice_mean,\n    \"test_patient_dice_ci_low\": dice_lo,\n    \"test_patient_dice_ci_high\": dice_hi,\n    \"test_patient_iou_mean\": iou_mean,\n    \"test_patient_iou_ci_low\": iou_lo,\n    \"test_patient_iou_ci_high\": iou_hi,\n}])\n\ntest_metrics_path = OUT_DIR / \"test_metrics.csv\"\ntest_metrics.to_csv(test_metrics_path, index=False)\n\nprint(\"Saved:\", test_metrics_path)\ntest_metrics\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Qualitative results (best model)\n\nWe export a clean panel: Input + GT overlay + Pred overlay for a few validation slices.\n","metadata":{}},{"cell_type":"code","source":"@torch.no_grad()\ndef qualitative_panel(model, loader, device, threshold, n=6, save_prefix=\"qual_panel\"):\n    xb, yb = next(iter(loader))\n    xb = xb.to(device)\n    yb = yb.to(device)\n\n    logits = model(xb)\n    probs = torch.sigmoid(logits)\n    pred = (probs > threshold).float()\n\n    n = min(n, xb.size(0))\n    fig, axes = plt.subplots(3, n, figsize=(13, 6))\n    for ax in axes.ravel():\n        paper_axes(ax)\n\n    for i in range(n):\n        img = np.clip(xb[i].detach().cpu().permute(1,2,0).numpy(), 0, 1)\n        gt  = yb[i,0].detach().cpu().numpy()\n        pr  = pred[i,0].detach().cpu().numpy()\n\n        axes[0, i].imshow(img); axes[0, i].set_title(f\"Input #{i}\"); axes[0, i].axis(\"off\")\n        axes[1, i].imshow(img); axes[1, i].imshow(gt, alpha=0.35, cmap=\"Reds\"); axes[1, i].set_title(\"GT\"); axes[1, i].axis(\"off\")\n        axes[2, i].imshow(img); axes[2, i].imshow(pr, alpha=0.35, cmap=\"Blues\"); axes[2, i].set_title(\"Pred\"); axes[2, i].axis(\"off\")\n\n    fig.suptitle(\"Qualitative segmentation results (best model)\", y=1.02)\n    plt.tight_layout()\n    plt.savefig(OUT_DIR / f\"{save_prefix}.png\", dpi=300, bbox_inches=\"tight\")\n    plt.savefig(OUT_DIR / f\"{save_prefix}.pdf\", dpi=300, bbox_inches=\"tight\")\n    plt.show()\n\nqualitative_panel(best_model, val_loader, device, best_t, n=6, save_prefix=\"fig_qualitative_val\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Next steps\n\n- Cross-dataset generalization (attach a second brain tumor dataset and test domain shift)\n- Robustness tests (noise/contrast shifts on test)\n- Statistical testing between ablation variants (paired bootstrap on patient Dice)\n- Calibration/threshold stability analysis\n","metadata":{}}]}