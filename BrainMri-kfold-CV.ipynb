{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":407317,"datasetId":181273,"databundleVersionId":422498},{"sourceType":"datasetVersion","sourceId":15010945,"datasetId":9608435,"databundleVersionId":15887327}],"dockerImageVersionId":31287,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from pathlib import Path\nimport glob\n\n# Finds the dataset folder that contains the checkpoints\nCKPT_MATCH = list(Path(\"/kaggle/input\").glob(\"**/best_attn1_freeze0.pt\"))\nif not CKPT_MATCH:\n    raise FileNotFoundError(\"best_attn1_freeze0.pt not found under /kaggle/input\")\n\nCKPT_ROOT = CKPT_MATCH[0].parent\nprint(\"CKPT_ROOT =\", CKPT_ROOT)\nprint(\"Files:\", sorted([p.name for p in CKPT_ROOT.glob(\"*.pt\")]))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\np = CKPT_ROOT / \"best_attn1_freeze0.pt\"\nobj = torch.load(p, map_location=\"cpu\")\n\nprint(type(obj))\nif isinstance(obj, dict):\n    print(\"dict keys (first 20):\", list(obj.keys())[:20])\n    # heuristic: state_dict usually has tensor values\n    any_tensor = any(hasattr(v, \"shape\") for v in obj.values())\n    print(\"looks_like_state_dict =\", any_tensor)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# From Notebook-3:\n- Conv blocks\n- Self-attention (if used)\n- ResNet encoder wrapper (if used)\n- Your final model class\n\n# Example placeholder name:\n- class OursResUNet(nn.Module)\n","metadata":{}},{"cell_type":"code","source":"import torch\n\ndef build_ours_from_ckpt(attn: int, freeze: int, ckpt_root: Path):\n    # IMPORTANT: Use the same model init args as Notebook-3\n    model = OursResUNet(use_attention=bool(attn), freeze_encoder=bool(freeze))  # <-- adjust to your signature\n\n    ckpt_path = ckpt_root / f\"best_attn{attn}_freeze{freeze}.pt\"\n    state = torch.load(ckpt_path, map_location=\"cpu\")\n    model.load_state_dict(state, strict=True)\n    return model\n\n# Quick check\n_ = build_ours_from_ckpt(attn=1, freeze=0, ckpt_root=CKPT_ROOT)\nprint(\"Loaded Ours attn=1 freeze=0\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def build_model(name):\n    if name == \"UNet\":\n        return UNet(in_ch=3, out_ch=1, base=32)\n    if name == \"ResUNet34\":\n        return ResUNet34(pretrained=True, out_ch=1)\n    if name == \"AttnUNet\":\n        return AttnUNet(in_ch=3, out_ch=1, base=32)\n\n    # ---- Ours (from Notebook-3 checkpoint) ----\n    if name == \"Ours_AttnFinetune\":\n        return build_ours_from_ckpt(attn=1, freeze=0, ckpt_root=CKPT_ROOT)\n\n    # Optional ablation variants:\n    if name == \"Ours_NoAttnFinetune\":\n        return build_ours_from_ckpt(attn=0, freeze=0, ckpt_root=CKPT_ROOT)\n    if name == \"Ours_NoAttnFrozen\":\n        return build_ours_from_ckpt(attn=0, freeze=1, ckpt_root=CKPT_ROOT)\n    if name == \"Ours_AttnFrozen\":\n        return build_ours_from_ckpt(attn=1, freeze=1, ckpt_root=CKPT_ROOT)\n\n    raise ValueError(\"Unknown model: \" + name)\n\nMODEL_NAMES = [\"UNet\", \"ResUNet34\", \"AttnUNet\", \"Ours_AttnFinetune\"]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"is_ours = mname.startswith(\"Ours_\")\nif is_ours:\n    model = build_model(mname).to(device)\n    model.eval()\n    # Tune threshold on fold-val and evaluate on fold-test (same as others)\n    tuned = tune_threshold_on_val(model, val_loader, val_ref, CFG[\"thresholds\"])\n    best_t = tuned[\"threshold\"]\n\n    test_fixed = eval_slice_and_patient(model, test_loader, test_ref, threshold=0.5)\n    test_tuned = eval_slice_and_patient(model, test_loader, test_ref, threshold=best_t)\n\n    all_rows.append({\n        \"fold\": fold_idx,\n        \"model\": mname,\n        \"best_epoch_by_val_patient_dice@0.5\": -1,\n        \"val_best_patient_dice@0.5\": np.nan,\n        \"val_best_threshold\": float(best_t),\n        \"test_patient_dice@0.5\": float(test_fixed[\"patient_dice_mean\"]),\n        \"test_patient_dice@tuned\": float(test_tuned[\"patient_dice_mean\"]),\n        \"test_slice_dice@0.5\": float(test_fixed[\"slice_dice_mean\"]),\n        \"test_slice_dice@tuned\": float(test_tuned[\"slice_dice_mean\"]),\n    })\n    continue\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}