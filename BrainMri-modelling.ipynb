{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":407317,"datasetId":181273,"databundleVersionId":422498}],"dockerImageVersionId":31287,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# LGG Brain MRI Segmentation — Transfer Learning + Self-Attention (ResNet-U-Net)\n\nThis notebook trains a segmentation model on the LGG FLAIR abnormality dataset:\n- Patient-level split to prevent leakage\n- Transfer learning (ImageNet pretrained ResNet34 encoder)\n- Bottleneck self-attention (multi-head attention on deep features)\n- Dice + BCE loss, Dice/IoU metrics\n- Paper-style plots (global matplotlib styling)\n\nOutputs saved to `/kaggle/working/`.\n","metadata":{}},{"cell_type":"code","source":"# If Kaggle already has these, this cell is harmless.\n!pip -q install albumentations==1.3.1 opencv-python-headless==4.9.0.80\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os, re, glob, random, math, time\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nimport torchvision\nfrom torchvision.models import resnet34, ResNet34_Weights\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# -------------------------------\n# ✅ GLOBAL PAPER-STYLE SETTINGS (as you provided)\n# -------------------------------\nplt.rcParams.update({\n    \"font.family\": \"serif\",\n    \"font.serif\": [\"Times New Roman\", \"Times\", \"DejaVu Serif\"],\n    \"font.size\": 12,\n\n    \"axes.labelsize\": 13,\n    \"axes.titlesize\": 13,\n    \"axes.linewidth\": 1.2,\n\n    \"xtick.labelsize\": 11,\n    \"ytick.labelsize\": 11,\n    \"xtick.major.size\": 6,\n    \"ytick.major.size\": 6,\n    \"xtick.minor.size\": 3,\n    \"ytick.minor.size\": 3,\n\n    \"legend.fontsize\": 11,\n    \"legend.frameon\": True,\n    \"legend.edgecolor\": \"0.4\",\n\n    \"grid.linestyle\": \":\",\n    \"grid.linewidth\": 0.7,\n    \"grid.alpha\": 0.85,\n})\n\ndef paper_axes(ax):\n    ax.minorticks_on()\n    ax.grid(True, which=\"major\", linestyle=\":\", linewidth=0.8)\n    ax.grid(True, which=\"minor\", linestyle=\":\", linewidth=0.5, alpha=0.7)\n\n    for spine in ax.spines.values():\n        spine.set_linewidth(1.2)\n\n    ax.tick_params(which=\"both\", direction=\"in\", top=True, right=True)\n\n# -------------------------------\n# Reproducibility\n# -------------------------------\nSEED = 7\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\n\ntorch.backends.cudnn.deterministic = False  # faster; OK with fixed seed\ntorch.backends.cudnn.benchmark = True\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"CFG = {\n    \"img_size\": 256,\n    \"batch_size\": 16,\n    \"num_workers\": 2,\n    \"epochs\": 12,\n    \"lr\": 3e-4,\n    \"weight_decay\": 1e-4,\n    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n    \"use_attention\": True,          # ablation knob\n    \"attn_heads\": 8,                # 512 channels / 8 heads works cleanly\n    \"threshold\": 0.5,\n}\n\nCFG\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Load dataset index (with safe fallback)\n\nPreferred:\n- Load `lgg_master_slices.csv` created by your EDA notebook.\n\nFallback:\n- Rebuild the dataframe directly from `/kaggle/input/**/kaggle_3m`.\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"KAGGLE_INPUT = Path(\"/kaggle/input\")\ncandidates = list(KAGGLE_INPUT.glob(\"**/kaggle_3m\"))\nprint(\"Found candidates:\", [str(p) for p in candidates[:10]])\n\nif len(candidates) == 0:\n    raise FileNotFoundError(\"Could not find 'kaggle_3m' under /kaggle/input. Attach the dataset to this notebook.\")\n\nDATA_ROOT = candidates[0]\nDATA_ROOT\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def to_key(path):\n    base = Path(path).name\n    if base.endswith(\"_mask.tif\"):\n        base = base.replace(\"_mask.tif\", \"\")\n    else:\n        base = base.replace(\".tif\", \"\")\n    return base\n\ndef patient_id_from_path(path):\n    return Path(path).parent.name\n\ndef slice_index_from_key(k):\n    m = re.search(r\"_(\\d+)$\", k)\n    return int(m.group(1)) if m else np.nan\n\nEDA_CSV = Path(\"/kaggle/working/eda_outputs/lgg_master_slices.csv\")\n\nif EDA_CSV.exists():\n    df = pd.read_csv(EDA_CSV)\n    print(\"Loaded:\", EDA_CSV, \"| rows:\", len(df), \"| patients:\", df[\"patient_id\"].nunique())\nelse:\n    all_tifs = sorted(glob.glob(str(DATA_ROOT / \"*\" / \"*.tif\")))\n    mask_tifs = sorted([p for p in all_tifs if p.endswith(\"_mask.tif\")])\n    img_tifs  = sorted([p for p in all_tifs if not p.endswith(\"_mask.tif\")])\n\n    img_map = {to_key(p): p for p in img_tifs}\n    msk_map = {to_key(p): p for p in mask_tifs}\n    keys = sorted(set(img_map.keys()) & set(msk_map.keys()))\n\n    df = pd.DataFrame({\n        \"key\": keys,\n        \"image_path\": [img_map[k] for k in keys],\n        \"mask_path\":  [msk_map[k] for k in keys],\n    })\n    df[\"patient_id\"] = df[\"image_path\"].apply(patient_id_from_path)\n    df[\"slice_idx\"] = df[\"key\"].apply(slice_index_from_key)\n\n    print(\"Built df | rows:\", len(df), \"| patients:\", df[\"patient_id\"].nunique())\n\ndf.head()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if \"split\" not in df.columns or df[\"split\"].isna().any():\n    patients = df[\"patient_id\"].drop_duplicates().tolist()\n    rng = np.random.default_rng(SEED)\n    rng.shuffle(patients)\n\n    n = len(patients)\n    train_pat = set(patients[: int(0.8*n)])\n    val_pat   = set(patients[int(0.8*n): int(0.9*n)])\n    test_pat  = set(patients[int(0.9*n):])\n\n    def assign_split(pid):\n        if pid in train_pat: return \"train\"\n        if pid in val_pat: return \"val\"\n        return \"test\"\n\n    df[\"split\"] = df[\"patient_id\"].apply(assign_split)\n\ndf[\"split\"].value_counts(), df.groupby(\"split\")[\"patient_id\"].nunique()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}