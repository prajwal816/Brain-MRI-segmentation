{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":407317,"datasetId":181273,"databundleVersionId":422498},{"sourceType":"datasetVersion","sourceId":15010945,"datasetId":9608435,"databundleVersionId":15887327}],"dockerImageVersionId":31287,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Notebook-4: Baselines + Patient-level k-fold CV + Threshold-tuning Claims\n\nGoals (conference-paper ready):\n1) Baselines: Plain U-Net, ResUNet (ResNet34 encoder), Attention U-Net (gated skips).\n2) Generalization: Patient-level k-fold CV (no leakage across folds).\n3) Positioning: Show how conclusions change when using:\n   - slice metrics vs patient metrics\n   - fixed threshold (0.5) vs validation-tuned threshold\n\nAll outputs saved to: `/kaggle/working/paper_outputs_nb4/`.\n","metadata":{}},{"cell_type":"code","source":"import os, re, glob, random, math, time\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom torchvision.models import resnet34, ResNet34_Weights\nimport torchvision.transforms.functional as TF\n\n# -------------------------------\n# Paper-style plots\n# -------------------------------\nplt.rcParams.update({\n    \"font.family\": \"serif\",\n    \"font.serif\": [\"Times New Roman\", \"Times\", \"DejaVu Serif\"],\n    \"font.size\": 12,\n    \"axes.labelsize\": 13,\n    \"axes.titlesize\": 13,\n    \"axes.linewidth\": 1.2,\n    \"xtick.labelsize\": 11,\n    \"ytick.labelsize\": 11,\n    \"xtick.major.size\": 6,\n    \"ytick.major.size\": 6,\n    \"xtick.minor.size\": 3,\n    \"ytick.minor.size\": 3,\n    \"legend.fontsize\": 11,\n    \"legend.frameon\": True,\n    \"legend.edgecolor\": \"0.4\",\n    \"grid.linestyle\": \":\",\n    \"grid.linewidth\": 0.7,\n    \"grid.alpha\": 0.85,\n})\ndef paper_axes(ax):\n    ax.minorticks_on()\n    ax.grid(True, which=\"major\", linestyle=\":\", linewidth=0.8)\n    ax.grid(True, which=\"minor\", linestyle=\":\", linewidth=0.5, alpha=0.7)\n    for spine in ax.spines.values():\n        spine.set_linewidth(1.2)\n    ax.tick_params(which=\"both\", direction=\"in\", top=True, right=True)\n\n# -------------------------------\n# Reproducibility\n# -------------------------------\nSEED = 7\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\ntorch.backends.cudnn.deterministic = False\ntorch.backends.cudnn.benchmark = True\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-03-02T05:22:18.574234Z","iopub.execute_input":"2026-03-02T05:22:18.574934Z","iopub.status.idle":"2026-03-02T05:22:18.589837Z","shell.execute_reply.started":"2026-03-02T05:22:18.574901Z","shell.execute_reply":"2026-03-02T05:22:18.589108Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"CFG = {\n    \"img_size\": 256,\n    \"batch_size\": 16,\n    \"num_workers\": 2,\n\n    \"epochs\": 8,\n    \"lr\": 3e-4,\n    \"weight_decay\": 1e-4,\n\n    \"k_folds\": 5,\n    \"val_frac_in_train\": 0.10,  # inside each fold's training pool\n    \"thresholds\": np.linspace(0.1, 0.9, 17),\n\n    \"fast_dev_run\": False,\n    \"fast_train_slices\": 500,\n    \"fast_val_slices\": 200,\n\n    \"amp\": True,\n}\n\nOUT_DIR = Path(\"/kaggle/working/paper_outputs_nb4\")\nOUT_DIR.mkdir(parents=True, exist_ok=True)\nOUT_DIR\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-03-02T05:22:18.591374Z","iopub.execute_input":"2026-03-02T05:22:18.591656Z","iopub.status.idle":"2026-03-02T05:22:18.606041Z","shell.execute_reply.started":"2026-03-02T05:22:18.591632Z","shell.execute_reply":"2026-03-02T05:22:18.605321Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"PosixPath('/kaggle/working/paper_outputs_nb4')"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"KAGGLE_INPUT = Path(\"/kaggle/input\")\ncandidates = list(KAGGLE_INPUT.glob(\"**/kaggle_3m\"))\nprint(\"Found candidates:\", [str(p) for p in candidates[:10]])\n\nif len(candidates) == 0:\n    raise FileNotFoundError(\"Could not find 'kaggle_3m' under /kaggle/input. Attach the dataset.\")\nDATA_ROOT = candidates[0]\nDATA_ROOT\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-03-02T05:22:18.606881Z","iopub.execute_input":"2026-03-02T05:22:18.607256Z","iopub.status.idle":"2026-03-02T05:22:33.853182Z","shell.execute_reply.started":"2026-03-02T05:22:18.607231Z","shell.execute_reply":"2026-03-02T05:22:33.852485Z"}},"outputs":[{"name":"stdout","text":"Found candidates: ['/kaggle/input/datasets/mateuszbuda/lgg-mri-segmentation/kaggle_3m', '/kaggle/input/datasets/mateuszbuda/lgg-mri-segmentation/lgg-mri-segmentation/kaggle_3m']\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"PosixPath('/kaggle/input/datasets/mateuszbuda/lgg-mri-segmentation/kaggle_3m')"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"def to_key(path):\n    base = Path(path).name\n    if base.endswith(\"_mask.tif\"):\n        base = base.replace(\"_mask.tif\", \"\")\n    else:\n        base = base.replace(\".tif\", \"\")\n    return base\n\ndef patient_id_from_path(path):\n    return Path(path).parent.name\n\ndef slice_index_from_key(k):\n    m = re.search(r\"_(\\d+)$\", k)\n    return int(m.group(1)) if m else np.nan\n\nall_tifs = sorted(glob.glob(str(DATA_ROOT / \"*\" / \"*.tif\")))\nmask_tifs = sorted([p for p in all_tifs if p.endswith(\"_mask.tif\")])\nimg_tifs  = sorted([p for p in all_tifs if not p.endswith(\"_mask.tif\")])\n\nimg_map = {to_key(p): p for p in img_tifs}\nmsk_map = {to_key(p): p for p in mask_tifs}\nkeys = sorted(set(img_map.keys()) & set(msk_map.keys()))\n\ndf = pd.DataFrame({\n    \"key\": keys,\n    \"image_path\": [img_map[k] for k in keys],\n    \"mask_path\":  [msk_map[k] for k in keys],\n})\ndf[\"patient_id\"] = df[\"image_path\"].apply(patient_id_from_path)\ndf[\"slice_idx\"] = df[\"key\"].apply(slice_index_from_key)\ndf = df.sort_values([\"patient_id\", \"slice_idx\", \"key\"]).reset_index(drop=True)\n\nprint(\"Slices:\", len(df), \"| Patients:\", df[\"patient_id\"].nunique())\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-03-02T05:22:33.854166Z","iopub.execute_input":"2026-03-02T05:22:33.854401Z","iopub.status.idle":"2026-03-02T05:22:34.015388Z","shell.execute_reply.started":"2026-03-02T05:22:33.854378Z","shell.execute_reply":"2026-03-02T05:22:34.014894Z"}},"outputs":[{"name":"stdout","text":"Slices: 3929 | Patients: 110\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"                       key                                         image_path  \\\n0  TCGA_CS_4941_19960909_1  /kaggle/input/datasets/mateuszbuda/lgg-mri-seg...   \n1  TCGA_CS_4941_19960909_2  /kaggle/input/datasets/mateuszbuda/lgg-mri-seg...   \n2  TCGA_CS_4941_19960909_3  /kaggle/input/datasets/mateuszbuda/lgg-mri-seg...   \n3  TCGA_CS_4941_19960909_4  /kaggle/input/datasets/mateuszbuda/lgg-mri-seg...   \n4  TCGA_CS_4941_19960909_5  /kaggle/input/datasets/mateuszbuda/lgg-mri-seg...   \n\n                                           mask_path             patient_id  \\\n0  /kaggle/input/datasets/mateuszbuda/lgg-mri-seg...  TCGA_CS_4941_19960909   \n1  /kaggle/input/datasets/mateuszbuda/lgg-mri-seg...  TCGA_CS_4941_19960909   \n2  /kaggle/input/datasets/mateuszbuda/lgg-mri-seg...  TCGA_CS_4941_19960909   \n3  /kaggle/input/datasets/mateuszbuda/lgg-mri-seg...  TCGA_CS_4941_19960909   \n4  /kaggle/input/datasets/mateuszbuda/lgg-mri-seg...  TCGA_CS_4941_19960909   \n\n   slice_idx  \n0          1  \n1          2  \n2          3  \n3          4  \n4          5  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>key</th>\n      <th>image_path</th>\n      <th>mask_path</th>\n      <th>patient_id</th>\n      <th>slice_idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TCGA_CS_4941_19960909_1</td>\n      <td>/kaggle/input/datasets/mateuszbuda/lgg-mri-seg...</td>\n      <td>/kaggle/input/datasets/mateuszbuda/lgg-mri-seg...</td>\n      <td>TCGA_CS_4941_19960909</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TCGA_CS_4941_19960909_2</td>\n      <td>/kaggle/input/datasets/mateuszbuda/lgg-mri-seg...</td>\n      <td>/kaggle/input/datasets/mateuszbuda/lgg-mri-seg...</td>\n      <td>TCGA_CS_4941_19960909</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>TCGA_CS_4941_19960909_3</td>\n      <td>/kaggle/input/datasets/mateuszbuda/lgg-mri-seg...</td>\n      <td>/kaggle/input/datasets/mateuszbuda/lgg-mri-seg...</td>\n      <td>TCGA_CS_4941_19960909</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TCGA_CS_4941_19960909_4</td>\n      <td>/kaggle/input/datasets/mateuszbuda/lgg-mri-seg...</td>\n      <td>/kaggle/input/datasets/mateuszbuda/lgg-mri-seg...</td>\n      <td>TCGA_CS_4941_19960909</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>TCGA_CS_4941_19960909_5</td>\n      <td>/kaggle/input/datasets/mateuszbuda/lgg-mri-seg...</td>\n      <td>/kaggle/input/datasets/mateuszbuda/lgg-mri-seg...</td>\n      <td>TCGA_CS_4941_19960909</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"def load_tif(path):\n    return np.array(Image.open(path))\n\ndef to_mask01(msk):\n    if msk.ndim == 3:\n        m = msk[..., 0]\n    else:\n        m = msk\n    return (m > 0).astype(np.uint8)\n\nclass TorchvisionAugment:\n    def __init__(self, train=True):\n        self.train = train\n\n    def __call__(self, img, msk):\n        img_t = TF.to_tensor(img)  # (3,H,W) float [0,1]\n        msk_t = torch.from_numpy(msk).unsqueeze(0).float()\n\n        if self.train:\n            if torch.rand(1).item() < 0.5:\n                img_t = TF.hflip(img_t); msk_t = TF.hflip(msk_t)\n            if torch.rand(1).item() < 0.2:\n                img_t = TF.vflip(img_t); msk_t = TF.vflip(msk_t)\n\n            angle = float((torch.rand(1).item() - 0.5) * 24.0)  # [-12,12]\n            img_t = TF.rotate(img_t, angle, interpolation=TF.InterpolationMode.BILINEAR)\n            msk_t = TF.rotate(msk_t, angle, interpolation=TF.InterpolationMode.NEAREST)\n\n            if torch.rand(1).item() < 0.25:\n                b = 0.9 + 0.2 * torch.rand(1).item()\n                c = 0.9 + 0.2 * torch.rand(1).item()\n                img_t = TF.adjust_brightness(img_t, b)\n                img_t = TF.adjust_contrast(img_t, c)\n\n            if torch.rand(1).item() < 0.15:\n                try:\n                    img_t = TF.gaussian_blur(img_t, kernel_size=[3,3], sigma=[0.1, 1.2])\n                except Exception:\n                    pass\n\n        return img_t.float(), msk_t.float()\n\ntrain_tfms = TorchvisionAugment(train=True)\neval_tfms  = TorchvisionAugment(train=False)\n\nclass LGGSegDataset(Dataset):\n    def __init__(self, df, tfms=None):\n        self.df = df.reset_index(drop=True)\n        self.tfms = tfms\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        r = self.df.iloc[idx]\n        img = load_tif(r.image_path)\n        msk = to_mask01(load_tif(r.mask_path))\n\n        if img.ndim == 2:\n            img = np.stack([img, img, img], axis=-1)\n\n        if self.tfms is None:\n            img_t = TF.to_tensor(img).float()\n            msk_t = torch.from_numpy(msk).unsqueeze(0).float()\n            return img_t, msk_t\n\n        return self.tfms(img, msk)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-03-02T05:22:34.016931Z","iopub.execute_input":"2026-03-02T05:22:34.017207Z","iopub.status.idle":"2026-03-02T05:22:34.027584Z","shell.execute_reply.started":"2026-03-02T05:22:34.017170Z","shell.execute_reply":"2026-03-02T05:22:34.026928Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"bce = nn.BCEWithLogitsLoss()\n\nclass DiceLoss(nn.Module):\n    def __init__(self, eps=1e-7):\n        super().__init__()\n        self.eps = eps\n    def forward(self, logits, targets):\n        probs = torch.sigmoid(logits)\n        num = 2.0 * (probs * targets).sum(dim=(2,3))\n        den = (probs + targets).sum(dim=(2,3)) + self.eps\n        return 1.0 - (num / den).mean()\n\ndef total_loss(logits, targets):\n    return 0.6 * bce(logits, targets) + 0.4 * DiceLoss()(logits, targets)\n\n@torch.no_grad()\ndef dice_iou_from_bin(pred_bin, targ, eps=1e-7):\n    inter = (pred_bin * targ).sum(dim=(2,3))\n    dice = (2*inter) / (pred_bin.sum(dim=(2,3)) + targ.sum(dim=(2,3)) + eps)\n    union = (pred_bin + targ - pred_bin*targ).sum(dim=(2,3)) + eps\n    iou = inter / union\n    return dice.squeeze(1), iou.squeeze(1)\n\n@torch.no_grad()\ndef eval_slice_and_patient(model, loader, df_ref, threshold=0.5):\n    model.eval()\n    ptr = 0\n    rows = []\n    losses = []\n\n    for xb, yb in loader:\n        bs = xb.size(0)\n        batch_df = df_ref.iloc[ptr:ptr+bs]\n        ptr += bs\n\n        xb = xb.to(device, non_blocking=True)\n        yb = yb.to(device, non_blocking=True)\n\n        logits = model(xb)\n        losses.append(float(total_loss(logits, yb).item()))\n\n        probs = torch.sigmoid(logits)\n        pred_bin = (probs > threshold).float()\n\n        dice_b, iou_b = dice_iou_from_bin(pred_bin, yb)\n        for i in range(bs):\n            rows.append({\n                \"patient_id\": batch_df.iloc[i][\"patient_id\"],\n                \"key\": batch_df.iloc[i][\"key\"],\n                \"slice_dice\": float(dice_b[i].item()),\n                \"slice_iou\": float(iou_b[i].item()),\n                \"gt_area\": float(yb[i,0].sum().item()),\n                \"pred_area\": float(pred_bin[i,0].sum().item()),\n            })\n\n    slice_df = pd.DataFrame(rows)\n    # patient metric = mean over slices, then mean over patients\n    pat_df = slice_df.groupby(\"patient_id\", as_index=False).agg(\n        patient_dice=(\"slice_dice\", \"mean\"),\n        patient_iou=(\"slice_iou\", \"mean\"),\n        mean_gt_area=(\"gt_area\", \"mean\"),\n    )\n\n    out = {\n        \"loss\": float(np.mean(losses)) if len(losses) else np.nan,\n        \"slice_dice_mean\": float(slice_df[\"slice_dice\"].mean()),\n        \"slice_iou_mean\": float(slice_df[\"slice_iou\"].mean()),\n        \"patient_dice_mean\": float(pat_df[\"patient_dice\"].mean()),\n        \"patient_iou_mean\": float(pat_df[\"patient_iou\"].mean()),\n        \"slice_df\": slice_df,\n        \"patient_df\": pat_df,\n    }\n    return out\n\n@torch.no_grad()\ndef tune_threshold_on_val(model, val_loader, val_ref, thresholds):\n    best = {\"threshold\": 0.5, \"patient_dice_mean\": -1}\n    for t in thresholds:\n        out = eval_slice_and_patient(model, val_loader, val_ref, threshold=float(t))\n        if out[\"patient_dice_mean\"] > best[\"patient_dice_mean\"]:\n            best = {\"threshold\": float(t), \"patient_dice_mean\": out[\"patient_dice_mean\"]}\n    return best\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-03-02T05:22:34.028421Z","iopub.execute_input":"2026-03-02T05:22:34.028695Z","iopub.status.idle":"2026-03-02T05:22:34.044948Z","shell.execute_reply.started":"2026-03-02T05:22:34.028674Z","shell.execute_reply":"2026-03-02T05:22:34.044346Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"class DoubleConv(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True),\n        )\n    def forward(self, x):\n        return self.net(x)\n\nclass Down(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super().__init__()\n        self.pool = nn.MaxPool2d(2)\n        self.conv = DoubleConv(in_ch, out_ch)\n    def forward(self, x):\n        return self.conv(self.pool(x))\n\nclass Up(nn.Module):\n    def __init__(self, in_ch, skip_ch, out_ch):\n        super().__init__()\n        self.up = nn.ConvTranspose2d(in_ch, out_ch, 2, stride=2)\n        self.conv = DoubleConv(out_ch + skip_ch, out_ch)\n    def forward(self, x, skip):\n        x = self.up(x)\n        if x.shape[-2:] != skip.shape[-2:]:\n            x = F.interpolate(x, size=skip.shape[-2:], mode=\"bilinear\", align_corners=False)\n        x = torch.cat([skip, x], dim=1)\n        return self.conv(x)\n\nclass UNet(nn.Module):\n    def __init__(self, in_ch=3, out_ch=1, base=32):\n        super().__init__()\n        self.inc = DoubleConv(in_ch, base)\n        self.d1 = Down(base, base*2)\n        self.d2 = Down(base*2, base*4)\n        self.d3 = Down(base*4, base*8)\n        self.d4 = Down(base*8, base*16)\n\n        self.u1 = Up(base*16, base*8, base*8)\n        self.u2 = Up(base*8, base*4, base*4)\n        self.u3 = Up(base*4, base*2, base*2)\n        self.u4 = Up(base*2, base, base)\n\n        self.outc = nn.Conv2d(base, out_ch, 1)\n\n    def forward(self, x):\n        x1 = self.inc(x)\n        x2 = self.d1(x1)\n        x3 = self.d2(x2)\n        x4 = self.d3(x3)\n        x5 = self.d4(x4)\n\n        x = self.u1(x5, x4)\n        x = self.u2(x,  x3)\n        x = self.u3(x,  x2)\n        x = self.u4(x,  x1)\n        return self.outc(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-03-02T05:22:34.045739Z","iopub.execute_input":"2026-03-02T05:22:34.046085Z","iopub.status.idle":"2026-03-02T05:22:34.058880Z","shell.execute_reply.started":"2026-03-02T05:22:34.046064Z","shell.execute_reply":"2026-03-02T05:22:34.058307Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"class AttentionGate(nn.Module):\n    def __init__(self, skip_ch, gate_ch, inter_ch):\n        super().__init__()\n        self.theta = nn.Sequential(nn.Conv2d(skip_ch, inter_ch, 1, bias=False),\n                                   nn.BatchNorm2d(inter_ch))\n        self.phi   = nn.Sequential(nn.Conv2d(gate_ch, inter_ch, 1, bias=False),\n                                   nn.BatchNorm2d(inter_ch))\n        self.psi   = nn.Sequential(nn.Conv2d(inter_ch, 1, 1, bias=True),\n                                   nn.Sigmoid())\n\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, skip, gate):\n        if gate.shape[-2:] != skip.shape[-2:]:\n            gate = F.interpolate(gate, size=skip.shape[-2:], mode=\"bilinear\", align_corners=False)\n        x = self.relu(self.theta(skip) + self.phi(gate))\n        attn = self.psi(x)\n        return skip * attn\n\nclass AttnUNet(nn.Module):\n    def __init__(self, in_ch=3, out_ch=1, base=32):\n        super().__init__()\n        self.inc = DoubleConv(in_ch, base)\n        self.d1 = Down(base, base*2)\n        self.d2 = Down(base*2, base*4)\n        self.d3 = Down(base*4, base*8)\n        self.d4 = Down(base*8, base*16)\n\n        self.up1 = nn.ConvTranspose2d(base*16, base*8, 2, stride=2)\n        self.ag1 = AttentionGate(skip_ch=base*8, gate_ch=base*8, inter_ch=base*4)\n        self.cv1 = DoubleConv(base*16, base*8)\n\n        self.up2 = nn.ConvTranspose2d(base*8, base*4, 2, stride=2)\n        self.ag2 = AttentionGate(skip_ch=base*4, gate_ch=base*4, inter_ch=base*2)\n        self.cv2 = DoubleConv(base*8, base*4)\n\n        self.up3 = nn.ConvTranspose2d(base*4, base*2, 2, stride=2)\n        self.ag3 = AttentionGate(skip_ch=base*2, gate_ch=base*2, inter_ch=base)\n        self.cv3 = DoubleConv(base*4, base*2)\n\n        self.up4 = nn.ConvTranspose2d(base*2, base, 2, stride=2)\n        self.ag4 = AttentionGate(skip_ch=base, gate_ch=base, inter_ch=base//2)\n        self.cv4 = DoubleConv(base*2, base)\n\n        self.outc = nn.Conv2d(base, out_ch, 1)\n\n    def forward(self, x):\n        x1 = self.inc(x)\n        x2 = self.d1(x1)\n        x3 = self.d2(x2)\n        x4 = self.d3(x3)\n        x5 = self.d4(x4)\n\n        g = self.up1(x5)\n        if g.shape[-2:] != x4.shape[-2:]:\n            g = F.interpolate(g, size=x4.shape[-2:], mode=\"bilinear\", align_corners=False)\n        x4a = self.ag1(x4, g)\n        x = self.cv1(torch.cat([x4a, g], dim=1))\n\n        g = self.up2(x)\n        if g.shape[-2:] != x3.shape[-2:]:\n            g = F.interpolate(g, size=x3.shape[-2:], mode=\"bilinear\", align_corners=False)\n        x3a = self.ag2(x3, g)\n        x = self.cv2(torch.cat([x3a, g], dim=1))\n\n        g = self.up3(x)\n        if g.shape[-2:] != x2.shape[-2:]:\n            g = F.interpolate(g, size=x2.shape[-2:], mode=\"bilinear\", align_corners=False)\n        x2a = self.ag3(x2, g)\n        x = self.cv3(torch.cat([x2a, g], dim=1))\n\n        g = self.up4(x)\n        if g.shape[-2:] != x1.shape[-2:]:\n            g = F.interpolate(g, size=x1.shape[-2:], mode=\"bilinear\", align_corners=False)\n        x1a = self.ag4(x1, g)\n        x = self.cv4(torch.cat([x1a, g], dim=1))\n\n        return self.outc(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-03-02T05:22:34.059621Z","iopub.execute_input":"2026-03-02T05:22:34.059868Z","iopub.status.idle":"2026-03-02T05:22:34.090888Z","shell.execute_reply.started":"2026-03-02T05:22:34.059849Z","shell.execute_reply":"2026-03-02T05:22:34.090217Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"class ResUNet34(nn.Module):\n    def __init__(self, pretrained=True, out_ch=1):\n        super().__init__()\n        weights = ResNet34_Weights.IMAGENET1K_V1 if pretrained else None\n        m = resnet34(weights=weights)\n\n        self.enc0 = nn.Sequential(m.conv1, m.bn1, m.relu)  # /2\n        self.pool = m.maxpool                              # /4\n        self.enc1 = m.layer1                               # /4\n        self.enc2 = m.layer2                               # /8\n        self.enc3 = m.layer3                               # /16\n        self.enc4 = m.layer4                               # /32\n\n        # Decoder (channels from resnet34: 64,64,128,256,512)\n        self.up1 = Up(in_ch=512, skip_ch=256, out_ch=256)\n        self.up2 = Up(in_ch=256, skip_ch=128, out_ch=128)\n        self.up3 = Up(in_ch=128, skip_ch=64,  out_ch=64)\n        self.up4 = Up(in_ch=64,  skip_ch=64,  out_ch=32)   # skip from enc0\n\n        self.outc = nn.Conv2d(32, out_ch, 1)\n\n    def forward(self, x):\n        x0 = self.enc0(x)     # (64, H/2, W/2)\n        x1 = self.pool(x0)    # (64, H/4, W/4)\n        x1 = self.enc1(x1)    # (64, H/4, W/4)\n        x2 = self.enc2(x1)    # (128, H/8, W/8)\n        x3 = self.enc3(x2)    # (256, H/16, W/16)\n        x4 = self.enc4(x3)    # (512, H/32, W/32)\n\n        x = self.up1(x4, x3)\n        x = self.up2(x,  x2)\n        x = self.up3(x,  x1)\n        x = self.up4(x,  x0)\n\n        x = F.interpolate(x, scale_factor=2, mode=\"bilinear\", align_corners=False)  # back to H,W\n        return self.outc(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-03-02T05:22:34.091774Z","iopub.execute_input":"2026-03-02T05:22:34.092029Z","iopub.status.idle":"2026-03-02T05:22:34.104372Z","shell.execute_reply.started":"2026-03-02T05:22:34.091990Z","shell.execute_reply":"2026-03-02T05:22:34.103806Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"def make_patient_folds(df, k=5, seed=7):\n    patients = df[\"patient_id\"].drop_duplicates().tolist()\n    rng = np.random.default_rng(seed)\n    rng.shuffle(patients)\n    folds = [patients[i::k] for i in range(k)]\n    return folds\n\nfolds = make_patient_folds(df, k=CFG[\"k_folds\"], seed=SEED)\n[len(f) for f in folds], sum(len(f) for f in folds)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-03-02T05:22:34.105277Z","iopub.execute_input":"2026-03-02T05:22:34.105514Z","iopub.status.idle":"2026-03-02T05:22:34.120002Z","shell.execute_reply.started":"2026-03-02T05:22:34.105470Z","shell.execute_reply":"2026-03-02T05:22:34.119303Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"([22, 22, 22, 22, 22], 110)"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"def split_for_fold(df, test_patients, val_frac=0.1, seed=7):\n    test_patients = set(test_patients)\n    rest = df[~df[\"patient_id\"].isin(test_patients)].copy()\n    test = df[df[\"patient_id\"].isin(test_patients)].copy()\n\n    rest_pat = rest[\"patient_id\"].drop_duplicates().tolist()\n    rng = np.random.default_rng(seed)\n    rng.shuffle(rest_pat)\n\n    n_val = max(1, int(round(val_frac * len(rest_pat))))\n    val_pat = set(rest_pat[:n_val])\n    train_pat = set(rest_pat[n_val:])\n\n    train = rest[rest[\"patient_id\"].isin(train_pat)].copy()\n    val   = rest[rest[\"patient_id\"].isin(val_pat)].copy()\n\n    train = train.sort_values([\"patient_id\",\"slice_idx\",\"key\"]).reset_index(drop=True)\n    val   = val.sort_values([\"patient_id\",\"slice_idx\",\"key\"]).reset_index(drop=True)\n    test  = test.sort_values([\"patient_id\",\"slice_idx\",\"key\"]).reset_index(drop=True)\n    return train, val, test\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-03-02T05:22:34.121022Z","iopub.execute_input":"2026-03-02T05:22:34.121354Z","iopub.status.idle":"2026-03-02T05:22:34.130607Z","shell.execute_reply.started":"2026-03-02T05:22:34.121333Z","shell.execute_reply":"2026-03-02T05:22:34.130058Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"def make_loaders(train_df, val_df, test_df):\n    if CFG[\"fast_dev_run\"]:\n        train_df = train_df.iloc[:CFG[\"fast_train_slices\"]].copy().reset_index(drop=True)\n        val_df   = val_df.iloc[:CFG[\"fast_val_slices\"]].copy().reset_index(drop=True)\n\n    train_ds = LGGSegDataset(train_df, tfms=train_tfms)\n    val_ds   = LGGSegDataset(val_df, tfms=eval_tfms)\n    test_ds  = LGGSegDataset(test_df, tfms=eval_tfms)\n\n    train_loader = DataLoader(train_ds, batch_size=CFG[\"batch_size\"], shuffle=True,\n                              num_workers=CFG[\"num_workers\"], pin_memory=True)\n    val_loader   = DataLoader(val_ds, batch_size=CFG[\"batch_size\"], shuffle=False,\n                              num_workers=CFG[\"num_workers\"], pin_memory=True)\n    test_loader  = DataLoader(test_ds, batch_size=CFG[\"batch_size\"], shuffle=False,\n                              num_workers=CFG[\"num_workers\"], pin_memory=True)\n    return (train_loader, val_loader, test_loader)\n\ndef train_model(model, train_loader, val_loader, val_ref, epochs, lr, wd):\n    model = model.to(device)\n    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n    scaler = torch.amp.GradScaler(\"cuda\", enabled=(device==\"cuda\" and CFG[\"amp\"]))\n\n    best = {\"epoch\": -1, \"val_patient_dice\": -1, \"state\": None}\n    history = []\n\n    for ep in range(1, epochs+1):\n        model.train()\n        losses = []\n        for xb, yb in train_loader:\n            xb = xb.to(device, non_blocking=True)\n            yb = yb.to(device, non_blocking=True)\n            opt.zero_grad(set_to_none=True)\n\n            with torch.amp.autocast(\"cuda\", enabled=(device==\"cuda\" and CFG[\"amp\"])):\n                logits = model(xb)\n                loss = total_loss(logits, yb)\n\n            scaler.scale(loss).backward()\n            scaler.step(opt)\n            scaler.update()\n\n            losses.append(float(loss.item()))\n\n        val_out = eval_slice_and_patient(model, val_loader, val_ref, threshold=0.5)\n        row = {\n            \"epoch\": ep,\n            \"train_loss\": float(np.mean(losses)),\n            \"val_loss\": val_out[\"loss\"],\n            \"val_patient_dice@0.5\": val_out[\"patient_dice_mean\"],\n            \"val_slice_dice@0.5\": val_out[\"slice_dice_mean\"],\n        }\n        history.append(row)\n\n        if val_out[\"patient_dice_mean\"] > best[\"val_patient_dice\"]:\n            best = {\"epoch\": ep, \"val_patient_dice\": val_out[\"patient_dice_mean\"],\n                    \"state\": {k:v.detach().cpu() for k,v in model.state_dict().items()}}\n\n    hist_df = pd.DataFrame(history)\n    model.load_state_dict(best[\"state\"])\n    return model, hist_df, best\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-03-02T05:22:34.131363Z","iopub.execute_input":"2026-03-02T05:22:34.131610Z","iopub.status.idle":"2026-03-02T05:22:34.157153Z","shell.execute_reply.started":"2026-03-02T05:22:34.131591Z","shell.execute_reply":"2026-03-02T05:22:34.156529Z"}},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":"# Classes from Notebook 3","metadata":{}},{"cell_type":"code","source":"class ConvBNReLU(nn.Module):\n    def __init__(self, in_ch, out_ch, k=3, p=1):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Conv2d(in_ch, out_ch, kernel_size=k, padding=p, bias=False),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True),\n        )\n    def forward(self, x):\n        return self.net(x)\n\nclass UpBlock(nn.Module):\n    def __init__(self, in_ch, skip_ch, out_ch):\n        super().__init__()\n        self.up = nn.ConvTranspose2d(in_ch, out_ch, kernel_size=2, stride=2)\n        self.conv1 = ConvBNReLU(out_ch + skip_ch, out_ch)\n        self.conv2 = ConvBNReLU(out_ch, out_ch)\n\n    def forward(self, x, skip):\n        x = self.up(x)\n        if x.shape[-2:] != skip.shape[-2:]:\n            x = F.interpolate(x, size=skip.shape[-2:], mode=\"bilinear\", align_corners=False)\n        x = torch.cat([x, skip], dim=1)\n        x = self.conv1(x)\n        x = self.conv2(x)\n        return x\n\nclass BottleneckMHSA(nn.Module):\n    def __init__(self, channels, heads=8, dropout=0.0):\n        super().__init__()\n        self.norm1 = nn.LayerNorm(channels)\n        self.attn = nn.MultiheadAttention(embed_dim=channels, num_heads=heads,\n                                          dropout=dropout, batch_first=True)\n        self.norm2 = nn.LayerNorm(channels)\n        self.ffn = nn.Sequential(\n            nn.Linear(channels, channels*4),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(channels*4, channels),\n        )\n\n    def forward(self, x):\n        b, c, h, w = x.shape\n        tokens = x.permute(0,2,3,1).reshape(b, h*w, c)\n        t = self.norm1(tokens)\n        attn_out, _ = self.attn(t, t, t, need_weights=False)\n        tokens = tokens + attn_out\n        t2 = self.norm2(tokens)\n        tokens = tokens + self.ffn(t2)\n        return tokens.reshape(b, h, w, c).permute(0,3,1,2)\n\nclass ResNet34UNetAttn(nn.Module):\n    def __init__(self, pretrained=True, use_attention=True, attn_heads=8):\n        super().__init__()\n        weights = ResNet34_Weights.IMAGENET1K_V1 if pretrained else None\n        self.encoder = resnet34(weights=weights)\n\n        self.conv1 = self.encoder.conv1\n        self.bn1   = self.encoder.bn1\n        self.relu  = self.encoder.relu\n        self.maxp  = self.encoder.maxpool\n\n        self.layer1 = self.encoder.layer1\n        self.layer2 = self.encoder.layer2\n        self.layer3 = self.encoder.layer3\n        self.layer4 = self.encoder.layer4\n\n        self.attn = BottleneckMHSA(512, heads=attn_heads) if use_attention else nn.Identity()\n\n        self.up3 = UpBlock(512, 256, 256)\n        self.up2 = UpBlock(256, 128, 128)\n        self.up1 = UpBlock(128, 64, 64)\n        self.up0 = UpBlock(64, 64, 64)\n\n        self.out = nn.Conv2d(64, 1, kernel_size=1)\n\n    def forward(self, x):\n        x0 = self.relu(self.bn1(self.conv1(x)))      # (B,64,128,128)\n        x1 = self.layer1(self.maxp(x0))              # (B,64,64,64)\n        x2 = self.layer2(x1)                         # (B,128,32,32)\n        x3 = self.layer3(x2)                         # (B,256,16,16)\n        x4 = self.layer4(x3)                         # (B,512,8,8)\n\n        x4 = self.attn(x4)\n\n        d3 = self.up3(x4, x3)\n        d2 = self.up2(d3, x2)\n        d1 = self.up1(d2, x1)\n        d0 = self.up0(d1, x0)\n\n        d0 = F.interpolate(d0, scale_factor=2, mode=\"bilinear\", align_corners=False)\n        return self.out(d0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-03-02T05:22:34.158031Z","iopub.execute_input":"2026-03-02T05:22:34.158619Z","iopub.status.idle":"2026-03-02T05:22:34.173312Z","shell.execute_reply.started":"2026-03-02T05:22:34.158596Z","shell.execute_reply":"2026-03-02T05:22:34.172663Z"}},"outputs":[],"execution_count":40},{"cell_type":"markdown","source":"# Comparsion","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\nimport glob\n\n# Finds the dataset folder that contains the checkpoints\nCKPT_MATCH = list(Path(\"/kaggle/input\").glob(\"**/best_attn1_freeze0.pt\"))\nif not CKPT_MATCH:\n    raise FileNotFoundError(\"best_attn1_freeze0.pt not found under /kaggle/input\")\n\nCKPT_ROOT = CKPT_MATCH[0].parent\nprint(\"CKPT_ROOT =\", CKPT_ROOT)\nprint(\"Files:\", sorted([p.name for p in CKPT_ROOT.glob(\"*.pt\")]))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-03-02T05:22:34.175418Z","iopub.execute_input":"2026-03-02T05:22:34.175730Z","iopub.status.idle":"2026-03-02T05:22:34.494610Z","shell.execute_reply.started":"2026-03-02T05:22:34.175701Z","shell.execute_reply":"2026-03-02T05:22:34.493991Z"}},"outputs":[{"name":"stdout","text":"CKPT_ROOT = /kaggle/input/datasets/katakuricharlotte/brainmri-notebook3-outputs\nFiles: ['best_attn0_freeze0.pt', 'best_attn0_freeze1.pt', 'best_attn1_freeze0.pt', 'best_attn1_freeze1.pt']\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"import torch\n\np = CKPT_ROOT / \"best_attn1_freeze0.pt\"\nobj = torch.load(p, map_location=\"cpu\")\n\nprint(type(obj))\nif isinstance(obj, dict):\n    print(\"dict keys (first 20):\", list(obj.keys())[:20])\n    # heuristic: state_dict usually has tensor values\n    any_tensor = any(hasattr(v, \"shape\") for v in obj.values())\n    print(\"looks_like_state_dict =\", any_tensor)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-03-02T05:22:34.495502Z","iopub.execute_input":"2026-03-02T05:22:34.495815Z","iopub.status.idle":"2026-03-02T05:22:34.619288Z","shell.execute_reply.started":"2026-03-02T05:22:34.495784Z","shell.execute_reply":"2026-03-02T05:22:34.618716Z"}},"outputs":[{"name":"stdout","text":"<class 'dict'>\ndict keys (first 20): ['model', 'config', 'CFG']\nlooks_like_state_dict = False\n","output_type":"stream"}],"execution_count":42},{"cell_type":"markdown","source":"# From Notebook-3:\n- Conv blocks\n- Self-attention (if used)\n- ResNet encoder wrapper (if used)\n- Your final model class\n\n# Example placeholder name (replace with your true class):\n- class OursResUNet(nn.Module):\n\n","metadata":{}},{"cell_type":"code","source":"import torch\nfrom pathlib import Path\n\ndef set_encoder_trainable(model, trainable: bool):\n    # your class stores encoder as model.encoder = resnet34(...)\n    for p in model.encoder.parameters():\n        p.requires_grad = trainable\n\ndef build_ours_from_ckpt(attn: int, freeze: int, ckpt_root: Path = None, attn_heads: int = 8):\n    if ckpt_root is None:\n        ckpt_root = CKPT_ROOT\n\n    ckpt_path = ckpt_root / f\"best_attn{attn}_freeze{freeze}.pt\"\n    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n\n    # Construct architecture (must match Notebook-3)\n    model = ResNet34UNetAttn(pretrained=True, use_attention=bool(attn), attn_heads=attn_heads)\n\n    # Apply freeze flag (freeze=1 => encoder not trainable)\n    set_encoder_trainable(model, trainable=(freeze == 0))\n\n    # Extract state_dict\n    if isinstance(ckpt, dict) and (\"model\" in ckpt):\n        state_dict = ckpt[\"model\"]\n    else:\n        state_dict = ckpt  # if it was saved as raw state_dict\n\n    model.load_state_dict(state_dict, strict=True)\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-03-02T05:22:34.620085Z","iopub.execute_input":"2026-03-02T05:22:34.620335Z","iopub.status.idle":"2026-03-02T05:22:34.626084Z","shell.execute_reply.started":"2026-03-02T05:22:34.620302Z","shell.execute_reply":"2026-03-02T05:22:34.625347Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"def build_model(name):\n    if name == \"UNet\":\n        return UNet(in_ch=3, out_ch=1, base=32)\n    if name == \"ResUNet34\":\n        return ResUNet34(pretrained=True, out_ch=1)\n    if name == \"AttnUNet\":\n        return AttnUNet(in_ch=3, out_ch=1, base=32)\n\n    # ---- Ours (Notebook-3 checkpoints) ----\n    if name == \"Ours_AttnFinetune\":\n        return build_ours_from_ckpt(attn=1, freeze=0, ckpt_root=CKPT_ROOT)\n\n    if name == \"Ours_NoAttnFinetune\":\n        return build_ours_from_ckpt(attn=0, freeze=0, ckpt_root=CKPT_ROOT)\n    if name == \"Ours_NoAttnFrozen\":\n        return build_ours_from_ckpt(attn=0, freeze=1, ckpt_root=CKPT_ROOT)\n    if name == \"Ours_AttnFrozen\":\n        return build_ours_from_ckpt(attn=1, freeze=1, ckpt_root=CKPT_ROOT)\n\n    raise ValueError(\"Unknown model: \" + name)\n\n\nMODEL_NAMES = [\"UNet\", \"ResUNet34\", \"AttnUNet\", \"Ours_AttnFinetune\"]\nMODEL_NAMES","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-03-02T05:22:34.626993Z","iopub.execute_input":"2026-03-02T05:22:34.627348Z","iopub.status.idle":"2026-03-02T05:22:34.638382Z","shell.execute_reply.started":"2026-03-02T05:22:34.627315Z","shell.execute_reply":"2026-03-02T05:22:34.637803Z"}},"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"['UNet', 'ResUNet34', 'AttnUNet', 'Ours_AttnFinetune']"},"metadata":{}}],"execution_count":44},{"cell_type":"markdown","source":"# quick sanity test","metadata":{}},{"cell_type":"code","source":"m = build_model(\"Ours_AttnFinetune\").to(device)\nm.eval()\nxb, yb = next(iter(val_loader))\nwith torch.no_grad():\n    out = m(xb.to(device))\nprint(\"OK. out:\", out.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-03-02T05:22:34.639183Z","iopub.execute_input":"2026-03-02T05:22:34.639402Z","iopub.status.idle":"2026-03-02T05:22:36.007234Z","shell.execute_reply.started":"2026-03-02T05:22:34.639382Z","shell.execute_reply":"2026-03-02T05:22:36.006568Z"}},"outputs":[{"name":"stdout","text":"OK. out: torch.Size([16, 1, 256, 256])\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"all_rows = []\nall_hist = []\n\nfor fold_idx in range(CFG[\"k_folds\"]):\n    test_pat = folds[fold_idx]\n    train_df, val_df, test_df = split_for_fold(\n        df, test_pat, val_frac=CFG[\"val_frac_in_train\"], seed=SEED + fold_idx\n    )\n\n    train_loader, val_loader, test_loader = make_loaders(train_df, val_df, test_df)\n\n    train_ref = train_df.reset_index(drop=True)\n    val_ref   = val_df.reset_index(drop=True)\n    test_ref  = test_df.reset_index(drop=True)\n\n    print(\n        f\"\\n=== Fold {fold_idx+1}/{CFG['k_folds']} | \"\n        f\"train_pat={train_df.patient_id.nunique()} \"\n        f\"val_pat={val_df.patient_id.nunique()} \"\n        f\"test_pat={test_df.patient_id.nunique()}\"\n    )\n\n    for mname in MODEL_NAMES:\n        torch.cuda.empty_cache()\n\n        is_ours = mname.startswith(\"Ours_\")\n\n        if is_ours:\n            model = build_model(mname).to(device)\n            model.eval()\n\n            tuned = tune_threshold_on_val(model, val_loader, val_ref, CFG[\"thresholds\"])\n            best_t = tuned[\"threshold\"]\n\n            test_fixed = eval_slice_and_patient(model, test_loader, test_ref, threshold=0.5)\n            test_tuned = eval_slice_and_patient(model, test_loader, test_ref, threshold=best_t)\n\n            all_rows.append({\n                \"fold\": fold_idx,\n                \"model\": mname,\n                \"best_epoch_by_val_patient_dice@0.5\": -1,\n                \"val_best_patient_dice@0.5\": np.nan,\n                \"val_best_threshold\": float(best_t),\n                \"test_patient_dice@0.5\": float(test_fixed[\"patient_dice_mean\"]),\n                \"test_patient_dice@tuned\": float(test_tuned[\"patient_dice_mean\"]),\n                \"test_slice_dice@0.5\": float(test_fixed[\"slice_dice_mean\"]),\n                \"test_slice_dice@tuned\": float(test_tuned[\"slice_dice_mean\"]),\n            })\n            continue\n\n        model = build_model(mname)\n\n        model, hist_df, best = train_model(\n            model,\n            train_loader=train_loader,\n            val_loader=val_loader,\n            val_ref=val_ref,\n            epochs=CFG[\"epochs\"],\n            lr=CFG[\"lr\"],\n            wd=CFG[\"weight_decay\"],\n        )\n\n        hist_df[\"fold\"] = fold_idx\n        hist_df[\"model\"] = mname\n        all_hist.append(hist_df)\n\n        tuned = tune_threshold_on_val(model, val_loader, val_ref, CFG[\"thresholds\"])\n        best_t = tuned[\"threshold\"]\n\n        test_fixed = eval_slice_and_patient(model, test_loader, test_ref, threshold=0.5)\n        test_tuned = eval_slice_and_patient(model, test_loader, test_ref, threshold=best_t)\n\n        all_rows.append({\n            \"fold\": fold_idx,\n            \"model\": mname,\n            \"best_epoch_by_val_patient_dice@0.5\": int(best[\"epoch\"]),\n            \"val_best_patient_dice@0.5\": float(best[\"val_patient_dice\"]),\n            \"val_best_threshold\": float(best_t),\n            \"test_patient_dice@0.5\": float(test_fixed[\"patient_dice_mean\"]),\n            \"test_patient_dice@tuned\": float(test_tuned[\"patient_dice_mean\"]),\n            \"test_slice_dice@0.5\": float(test_fixed[\"slice_dice_mean\"]),\n            \"test_slice_dice@tuned\": float(test_tuned[\"slice_dice_mean\"]),\n        })\n\ncv_df = pd.DataFrame(all_rows)\n\nif len(all_hist) > 0:\n    hist_all = pd.concat(all_hist, ignore_index=True)\nelse:\n    hist_all = pd.DataFrame()\n\ncv_csv = OUT_DIR / \"cv_results.csv\"\nhist_csv = OUT_DIR / \"cv_history.csv\"\n\ncv_df.to_csv(cv_csv, index=False)\nhist_all.to_csv(hist_csv, index=False)\n\nprint(\"Saved:\", cv_csv)\nprint(\"Saved:\", hist_csv)\n\ncv_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-03-02T05:22:36.008626Z","iopub.execute_input":"2026-03-02T05:22:36.008876Z"}},"outputs":[{"name":"stdout","text":"\n=== Fold 1/5 | train_pat=79 val_pat=9 test_pat=22\n\n=== Fold 2/5 | train_pat=79 val_pat=9 test_pat=22\n\n=== Fold 3/5 | train_pat=79 val_pat=9 test_pat=22\n\n=== Fold 4/5 | train_pat=79 val_pat=9 test_pat=22\n\n=== Fold 5/5 | train_pat=79 val_pat=9 test_pat=22\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"def mean_std(x):\n    return float(np.mean(x)), float(np.std(x, ddof=1)) if len(x) > 1 else 0.0\n\nagg_rows = []\nfor mname in MODEL_NAMES:\n    sub = cv_df[cv_df[\"model\"] == mname]\n    mu_pt_fixed, sd_pt_fixed = mean_std(sub[\"test_patient_dice@0.5\"])\n    mu_pt_tune,  sd_pt_tune  = mean_std(sub[\"test_patient_dice@tuned\"])\n    mu_sl_fixed, sd_sl_fixed = mean_std(sub[\"test_slice_dice@0.5\"])\n    mu_sl_tune,  sd_sl_tune  = mean_std(sub[\"test_slice_dice@tuned\"])\n    mu_t, sd_t = mean_std(sub[\"val_best_threshold\"])\n\n    agg_rows.append({\n        \"model\": mname,\n        \"val_threshold_mean\": mu_t, \"val_threshold_std\": sd_t,\n        \"test_patient_dice@0.5_mean\": mu_pt_fixed, \"test_patient_dice@0.5_std\": sd_pt_fixed,\n        \"test_patient_dice@tuned_mean\": mu_pt_tune, \"test_patient_dice@tuned_std\": sd_pt_tune,\n        \"test_slice_dice@0.5_mean\": mu_sl_fixed, \"test_slice_dice@0.5_std\": sd_sl_fixed,\n        \"test_slice_dice@tuned_mean\": mu_sl_tune, \"test_slice_dice@tuned_std\": sd_sl_tune,\n    })\n\nagg_df = pd.DataFrame(agg_rows).sort_values(\"test_patient_dice@tuned_mean\", ascending=False).reset_index(drop=True)\n\nagg_csv = OUT_DIR / \"cv_aggregate_mean_std.csv\"\nagg_df.to_csv(agg_csv, index=False)\n\nlatex_df = agg_df.copy()\nfor c in latex_df.columns:\n    if c != \"model\":\n        latex_df[c] = latex_df[c].map(lambda v: f\"{v:.4f}\")\nlatex_tex = OUT_DIR / \"cv_aggregate_mean_std.tex\"\nlatex_df.to_latex(latex_tex, index=False)\n\nprint(\"Saved:\", agg_csv)\nprint(\"Saved:\", latex_tex)\nagg_df\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def rank_models(series_by_model):\n    s = series_by_model.sort_values(ascending=False)\n    return {m: int(i+1) for i, m in enumerate(s.index.tolist())}\n\nr_slice_fixed = rank_models(agg_df.set_index(\"model\")[\"test_slice_dice@0.5_mean\"])\nr_patient_tuned = rank_models(agg_df.set_index(\"model\")[\"test_patient_dice@tuned_mean\"])\n\nrank_rows = []\nfor m in MODEL_NAMES:\n    rank_rows.append({\n        \"model\": m,\n        \"rank_by_slice_dice@0.5\": r_slice_fixed[m],\n        \"rank_by_patient_dice@tuned\": r_patient_tuned[m],\n        \"rank_shift\": r_slice_fixed[m] - r_patient_tuned[m],\n    })\n\nrank_df = pd.DataFrame(rank_rows).sort_values(\"rank_by_patient_dice@tuned\").reset_index(drop=True)\nrank_csv = OUT_DIR / \"ranking_shift.csv\"\nrank_df.to_csv(rank_csv, index=False)\nprint(\"Saved:\", rank_csv)\nrank_df\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(7.0, 4.0))\ndata = [cv_df[cv_df[\"model\"]==m][\"test_patient_dice@tuned\"].values for m in MODEL_NAMES]\nax.boxplot(data, labels=MODEL_NAMES, showmeans=True)\nax.set_title(\"Patient Dice across folds (tuned threshold)\")\nax.set_ylabel(\"Patient Dice\")\npaper_axes(ax)\nfig.tight_layout()\n\npng = OUT_DIR / \"boxplot_patient_dice_tuned.png\"\nfig.savefig(png, dpi=200, bbox_inches=\"tight\")\nplt.show()\nprint(\"Saved:\", png)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(7.0, 4.0))\n\nx = np.arange(len(agg_df))\nmeans = agg_df[\"test_patient_dice@tuned_mean\"].values\nstds  = agg_df[\"test_patient_dice@tuned_std\"].values\nlabels = agg_df[\"model\"].values\n\nax.bar(x, means, yerr=stds, capsize=5, color=\"gray\", edgecolor=\"black\")\nax.set_xticks(x, labels)\nax.set_ylabel(\"Patient Dice (mean Â± std)\")\nax.set_title(\"k-fold CV performance (patient-level, tuned threshold)\")\npaper_axes(ax)\n\nfig.tight_layout()\npng = OUT_DIR / \"bar_patient_dice_tuned_mean_std.png\"\nfig.savefig(png, dpi=200, bbox_inches=\"tight\")\nplt.show()\nprint(\"Saved:\", png)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}